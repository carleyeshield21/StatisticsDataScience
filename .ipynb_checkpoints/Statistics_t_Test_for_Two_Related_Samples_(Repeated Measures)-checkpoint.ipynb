{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3880a96-892d-4394-98b9-c57a2515b3b4",
   "metadata": {},
   "source": [
    "#### DIFFERENCE SCORE (D)\n",
    "$D = X_1-X_2$\n",
    "\n",
    "#### MEAN DIFFERENCE SCORE ($\\overline{D}$)\n",
    "\n",
    "$\\overline{D} = \\dfrac{\\Sigma{D}}{n}$\n",
    "\n",
    "#### Statistical Hypothesis\n",
    "\n",
    "Null Hypotheis: $H_0: \\mu_D \\leq 0$\n",
    "\n",
    "Alternative/Research Hypotheis: $H_1: \\mu_D > 0$\n",
    "\n",
    "#### Two Other Possible Alternative Hypotheses\n",
    "$H_0: \\mu_D < 0$ translates into a one-tailed test with the lower tail critical, and a nondirectional hypothesis\n",
    "\n",
    "$H_0: \\mu_D \\neq 0$ translates into a two-tailed test\n",
    "\n",
    "#### SAMPLING DISTRIBUTION OF $\\overline{D}$\n",
    "\n",
    "$\\mu_{\\overline{D}}=\\mu_{D}$\n",
    "\n",
    "#### Standard error\n",
    "\n",
    "$\\sigma_{\\overline{D}}=\\dfrac{{\\sigma}_D}{\\sqrt{n}}$\n",
    "\n",
    "#### t Test\n",
    "\n",
    "$t = \\dfrac{(sample~mean~difference)-(hypothesized~population~mean~difference)}{estimated~standard~error}$\n",
    "\n",
    "Expressed in symbols, t RATIO FOR TWO POPULATION MEANS (TWO RELATED SAMPLES)\n",
    "\n",
    "$t = \\dfrac{\\overline{D}-\\mu_{D_{hyp}}}{S_\\overline{D}}$\n",
    "\n",
    "which has a t sampling distribution with n – 1 degrees of freedom. $\\overline{D}$ represents the sample mean of the difference scores; $\\mu_{D_{hyp}}$ represents the hypothesized population mean (of zero) for the difference scores; and $S_\\overline{D}$ represents the estimated standard error of $\\overline{D}$\n",
    "\n",
    "### Sample Sums of Squares\n",
    "$SS_D=\\Sigma{D}^2-\\dfrac{(\\Sigma{D})^2}{n}$\n",
    "\n",
    "#### SAMPLE STANDARD DEVIATION, $S_D$\n",
    "\n",
    "$S_D = \\sqrt{\\dfrac{SS_D}{n-1}}$\n",
    "\n",
    "#### ESTIMATED STANDARD ERROR, $S_\\overline{D}$\n",
    "\n",
    "$S_\\overline{D}=\\dfrac{S_D}{\\sqrt{n}}$\n",
    "\n",
    "#### CONFIDENCE INTERVAL FOR μD (TWO RELATED SAMPLES)\n",
    "\n",
    "$\\overline{D} \\pm (t_{conf})(S_{\\overline{D}})$\n",
    "\n",
    "where $\\overline{D}$ represents the sample mean of the difference scores; $t_{conf}$ represents a number (distributed with n – 1 degrees of freedom) from the t tables, which satisfies the confidence specifications; and $S_\\overline{D}$ represents the estimated standard error defined in ESTIMATED STANDARD ERROR, $S_\\overline{D}$\n",
    "\n",
    "$S_\\overline{D}=\\dfrac{S_D}{\\sqrt{n}}$\n",
    "\n",
    "#### STANDARDIZED EFFECT SIZE, COHEN’S d (TWO RELATED SAMPLES)\n",
    "\n",
    "$d=\\dfrac{\\overline{D}}{S_D}$\n",
    "\n",
    "#### SUMMARY OF t TESTS FOR POPULATION MEANS\n",
    "\n",
    "\\begin{array}{|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{TYPE OF\n",
    "SAMPLE} & \\textbf{SAMPLE\n",
    "MEAN} & \\textbf{NULL\n",
    "HYPOTHESIS*} & \\textbf{STANDARD\n",
    "ERROR} & \\textbf{t RATIO} & \\textbf{DEGREES OF\n",
    "FREEDOM} \\\\\n",
    "\\hline\n",
    "One~sample & \\overline{X} & H_0:\\mu=some~number & S_{\\overline{X}} & \\dfrac{\\overline{X}-\\mu_{hyp}}{S_{\\overline{X}}} & n-1 \\\\\n",
    "\\hline\n",
    "Two~independent~samples~(no~pairing) & \\overline{X}_1-\\overline{X}_2 & H_0:\\mu_1-\\mu_2=0 & S_{\\overline{X}_1-\\overline{X}_2} & \\dfrac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)_{hyp}}{S_{\\overline{X}_1-\\overline{X}_2}} & n_1+n_2-2 \\\\\n",
    "\\hline\n",
    "Two~~related~samples~(pairs~of~observations) & \\overline{D} & H_0:\\mu_D=0 & S_{\\overline{D}} & \\dfrac{\\overline{D}-\\mu_{D_{hyp}}}{S_{\\overline{D}}} & n – 1~(where~n~refers~to~pairs~of~observations) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "$*$ For a two-tailed test.\n",
    "\n",
    "#### t RATIO FOR A SINGLE POPULATION CORRELATION COEFFICIENT\n",
    "\n",
    "$t=\\dfrac{r-\\rho_{hyp}}{\\sqrt{\\dfrac{1-r^2}{n-2}}}$\n",
    "\n",
    "where r refers to the sample correlation coefficient, $\\rho_{hyp}$ refers to the hypothesized population correlation coefficient (which always must equal zero); and n refers to the number of pairs of observations. The expression in the denominator represents the estimated standard error of the sample correlation coefficient. As implied by the term at the bottom of this expression, the sampling distribution of t has n – 2 degrees of freedom. When pairs of observations are represented as points in a scatterplot, r assumes that the cluster of points approximates a straight line. Two degrees of freedom are lost because only n – 2 points are free to vary about some straight line that, itself, always depends on two points.\n",
    "\n",
    "#### CORRELATION COEFFICIENT (COMPUTATION FORMULA)\n",
    "\n",
    "$r = \\frac{SP_{xy}}{\\sqrt{SS_xSS_y}}$\n",
    "\n",
    "#### The statistical hypotheses must be selected from among the following three possibilities, where μD represents the population mean for all difference scores:\n",
    "\n",
    "Non-directional:\n",
    "\n",
    "$H_0:\\mu_D=0$;\n",
    "$H_0:\\mu_D \\neq 0$\n",
    "\n",
    "Directional, lower tail critical:\n",
    "\n",
    "$H_0:\\mu_D \\geq 0$;\n",
    "$H_0:\\mu_D < 0$\n",
    "\n",
    "Directional, upper tail critical:\n",
    "\n",
    "$H_0:\\mu_D \\leq 0$;\n",
    "$H_0:\\mu_D > 0$\n",
    "\n",
    "The t ratio for two related samples has a sampling distribution with n – 1 degrees of freedom, given that n equals the number of paired observations. A confidence interval can be constructed for estimating μD. A single interpretation is possible only if the limits of the interval have the same sign, either both positive or both negative.\n",
    "\n",
    "If the t test is statistically significant, Cohen’s d can be used as a standardized estimate of effect size. When using t for two related samples, you must assume that the population of difference scores is normally distributed. You need not be too concerned about violations of this assumption as long as sample sizes are relatively large. To test the hypothesis that the population correlation coefficient equals zero, use a new t ratio with n – 2 degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e246fe-2bcf-492f-8cb8-c18bbf3da85e",
   "metadata": {},
   "source": [
    "#### SUMMARY OF t TESTS FOR POPULATION MEANS\n",
    "\n",
    "\\begin{array}{|c|c|c|c|c|c|}\n",
    "\\hline\n",
    "\\textbf{TYPE OF\n",
    "SAMPLE} & \\textbf{SAMPLE\n",
    "MEAN} & \\textbf{NULL\n",
    "HYPOTHESIS*} & \\textbf{STANDARD\n",
    "ERROR} & \\textbf{t RATIO} & \\textbf{DEGREES OF\n",
    "FREEDOM} \\\\\n",
    "\\hline\n",
    "One~sample & \\overline{X} & H_0:\\mu=some~number & S_{\\overline{X}} & \\dfrac{\\overline{X}-\\mu_{hyp}}{S_{\\overline{X}}} & n-1 \\\\\n",
    "\\hline\n",
    "Two~independent~samples~(no~pairing) & \\overline{X}_1-\\overline{X}_2 & H_0:\\mu_1-\\mu_2=0 & S_{\\overline{X}_1-\\overline{X}_2} & \\dfrac{(\\overline{X}_1-\\overline{X}_2)-(\\mu_1-\\mu_2)_{hyp}}{S_{\\overline{X}_1-\\overline{X}_2}} & n_1+n_2-2 \\\\\n",
    "\\hline\n",
    "Two~~related~samples~(pairs~of~observations) & \\overline{D} & H_0:\\mu_D=0 & S_{\\overline{D}} & \\dfrac{\\overline{D}-\\mu_{D_{hyp}}}{S_{\\overline{D}}} & n – 1~(where~n~refers~to~pairs~of~observations) \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "\n",
    "$*$ For a two-tailed test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af42059-d683-4665-a708-8396cacbd1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1_mean = 11\n",
      "X2_mean = 6\n",
      "[5, 2, 7, 5, 6, 5]\n",
      "D_mean = 5\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import math\n",
    "\n",
    "X1 = [12,5,11,11,9,18]\n",
    "X2 = [7,3,4,6,3,13]\n",
    "\n",
    "X1_mean = statistics.mean(X1)\n",
    "X2_mean = statistics.mean(X2)\n",
    "print(f'X1_mean = {X1_mean}\\nX2_mean = {X2_mean}')\n",
    "\n",
    "D = [X1[n]-X2[n] for n in range(0,len(X1))]\n",
    "print(D)\n",
    "D_mean = statistics.mean(D)\n",
    "print(f'D_mean = {D_mean}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6bff64-56b1-4817-8ad7-4659c13bd0ff",
   "metadata": {},
   "source": [
    "#### Function for t Test for repeated measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02f0c94-d5ac-4be8-9242-98e6f8d43656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_overline = 5\n",
      "sum_D = 30\n",
      "sq_of_each_D = [25, 4, 49, 25, 36, 25]\n",
      "sum_of_sq_of_each_D = 164\n",
      "SSD = 14.0\n",
      "sample_standard_deviation_SD = 1.6733200530681511\n",
      "est_std_error = 0.6831300510639733\n",
      "t_ratio = 7.319250547113998\n",
      "Cohen's d = 2.988071523335984\n"
     ]
    }
   ],
   "source": [
    "# CALCULATIONS FOR THE t TEST: REPEATED MEASURES (EPO EXPERIMENT)\n",
    "X1 = [12,5,11,11,9,18]\n",
    "X2 = [7,3,4,6,3,13]\n",
    "def t_test_repeated_measures(a,b):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    n = len(a)\n",
    "    X1_mean = statistics.mean(X1)\n",
    "    X2_mean = statistics.mean(X2)\n",
    "    D_overline = X1_mean - X2_mean\n",
    "    print(f'D_overline = {D_overline}')\n",
    "    \n",
    "    D = [X1[n]-X2[n] for n in range(0,len(X1))]\n",
    "    # print(f'D = {D}')\n",
    "\n",
    "    sum_D = sum(D)\n",
    "    print(f'sum_D = {sum_D}')\n",
    "\n",
    "    sq_of_each_D = [d**2 for d in D]\n",
    "    print(f'sq_of_each_D = {sq_of_each_D}')\n",
    "\n",
    "    sum_of_sq_of_each_D = sum(sq_of_each_D)\n",
    "    print(f'sum_of_sq_of_each_D = {sum_of_sq_of_each_D}')\n",
    "\n",
    "    SSD = sum_of_sq_of_each_D - (sum_D**2/n)\n",
    "    print(f'SSD = {SSD}')\n",
    "\n",
    "    sample_standard_deviation_SD = math.sqrt(SSD/(n-1))\n",
    "    print(f'sample_standard_deviation_SD = {sample_standard_deviation_SD}')\n",
    "\n",
    "    est_std_error = sample_standard_deviation_SD/math.sqrt(n)\n",
    "    print(f'est_std_error = {est_std_error}')\n",
    "\n",
    "    t_ratio = (D_overline-0)/est_std_error\n",
    "    print(f't_ratio = {t_ratio}')\n",
    "\n",
    "    d = D_overline/sample_standard_deviation_SD\n",
    "    print(f\"Cohen's d = {d}\")\n",
    "t_test_repeated_measures(X1,X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c3e891-5619-4349-a206-d2e80b3469df",
   "metadata": {},
   "source": [
    "#### Markdown for CALCULATIONS FOR THE t TEST: REPEATED MEASURES (EPO EXPERIMENT)\n",
    "$\\overline{D}=5$\n",
    "\n",
    "$\\Sigma{D}=30$\n",
    "\n",
    "$\\Sigma{D^2}=164$\n",
    "\n",
    "$SS_D=14.0$\n",
    "\n",
    "$S_D=1.6733200530681511$\n",
    "\n",
    "$S_\\overline{D}=0.6831300510639733$\n",
    "\n",
    "$t=7.319250547113998$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63008343-7d4a-4447-9bfb-b912c4edef22",
   "metadata": {},
   "source": [
    "#### Progress Check *15.2 An investigator tests a claim that vitamin C reduces the severity of common colds. To eliminate the variability due to different family environments, pairs of children from the same family are randomly assigned to either a treatment group that receives vitamin C or a control group that receives fake vitamin C. Each child estimates, on a 10-point scale, the severity of their colds during the school year. The following scores are obtained for ten pairs of children:\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{PAIR NUMBER} & \\text{VITAMIN C (X1)} & \\text{FAKE VITAMIN C (X2)} \\\\\n",
    "\\hline\n",
    "1 & 2 & 3 \\\\\n",
    "2 & 5 & 4 \\\\\n",
    "3 & 7 & 9 \\\\\n",
    "4 & 0 & 3 \\\\\n",
    "5 & 3 & 5 \\\\\n",
    "6 & 7 & 7 \\\\\n",
    "7 & 4 & 6 \\\\\n",
    "8 & 5 & 8 \\\\\n",
    "9 & 1 & 2 \\\\\n",
    "10 & 3 & 5 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Using t, test the null hypothesis at the .05 level of significance.\n",
    "\n",
    "#### Progress Check 15.3 Referring to the vitamin C experiment in Question 15.2, construct and interpret a 95 percent confidence interval for the population mean difference score.\n",
    "\n",
    "#### Progress Check *15.4 For the vitamin C experiment in Question 15.2, estimate and interpret the standardized effect size, d, given a mean, $\\overline{D}$, of –1.50 days and a standard deviation, $S_D$, of 1.27 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d29111c-e788-4cd1-9733-e79aa5dc1628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_overline = -1.5\n",
      "sum_D = -15\n",
      "sum_of_sq_of_each_D = 37\n",
      "SSD = 14.5\n",
      "sample_standard_deviation_SD = 1.2692955176439846\n",
      "est_std_error = 0.40138648595974313\n",
      "t_ratio = -3.7370465934182993\n",
      "Cohen's d = -1.181757895737503\n",
      "CI1 = -2.4079362312409387\n",
      "CI2 = -0.5920637687590611\n"
     ]
    }
   ],
   "source": [
    "X1 = [2,5,7,0,3,7,4,5,1,3]\n",
    "X2 = [3,4,9,3,5,7,6,8,2,5]\n",
    "# X1 = [12, 5, 11, 11, 9, 18]\n",
    "# X2 = [7, 3, 4, 6, 3, 13]\n",
    "def t_test_repeated_measures(a,b):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    n = len(a)\n",
    "    X1_mean = statistics.mean(X1)\n",
    "    X2_mean = statistics.mean(X2)\n",
    "    D_overline = X1_mean - X2_mean\n",
    "    print(f'D_overline = {D_overline}')\n",
    "    \n",
    "    D = [X1[n]-X2[n] for n in range(0,len(X1))]\n",
    "    # print(f'D = {D}')\n",
    "\n",
    "    sum_D = sum(D)\n",
    "    print(f'sum_D = {sum_D}')\n",
    "\n",
    "    sq_of_each_D = [d**2 for d in D]\n",
    "    # print(f'sq_of_each_D = {sq_of_each_D}')\n",
    "\n",
    "    sum_of_sq_of_each_D = sum(sq_of_each_D)\n",
    "    print(f'sum_of_sq_of_each_D = {sum_of_sq_of_each_D}')\n",
    "\n",
    "    SSD = sum_of_sq_of_each_D - (sum_D**2/n)\n",
    "    print(f'SSD = {SSD}')\n",
    "\n",
    "    sample_standard_deviation_SD = math.sqrt(SSD/(n-1))\n",
    "    print(f'sample_standard_deviation_SD = {sample_standard_deviation_SD}')\n",
    "\n",
    "    est_std_error = sample_standard_deviation_SD/math.sqrt(n)\n",
    "    print(f'est_std_error = {est_std_error}')\n",
    "\n",
    "    t_ratio = (D_overline-0)/est_std_error\n",
    "    print(f't_ratio = {t_ratio}')\n",
    "\n",
    "    d = D_overline/sample_standard_deviation_SD\n",
    "    print(f\"Cohen's d = {d}\")\n",
    "\n",
    "    # At 95% confidence level, significance level of 0.05, df=10-1=9, two-tailed test, t_value=2.262\n",
    "    CI1 = D_overline - (2.262*est_std_error)\n",
    "    CI2 = D_overline + (2.262*est_std_error)\n",
    "    print(f'CI1 = {CI1}\\nCI2 = {CI2}')\n",
    "t_test_repeated_measures(X1,X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5ba86-422e-4be7-8a67-5bc588f949e9",
   "metadata": {},
   "source": [
    "#### Markdown Progress Check *15.2\n",
    "\n",
    "### Statistical Hypothesis\n",
    "\n",
    "Null Hypotheis: $H_0: \\mu_D \\leq 0$\n",
    "\n",
    "$\\overline{D}=-1.5$\n",
    "\n",
    "$\\Sigma{D}=-15$\n",
    "\n",
    "$\\Sigma{D^2}=37$\n",
    "\n",
    "$SS_D=14.5$\n",
    "\n",
    "$S_D=1.2692955176439846$\n",
    "\n",
    "$S_\\overline{D}=0.40138648595974313$\n",
    "\n",
    "$t=-3.7370465934182993$\n",
    "\n",
    "$d=-1.181757895737503$\n",
    "\n",
    "At 95% confidence, significance level of 0.05, df=9, one-tailed test, t_value=±1.833, since t_ratio=-3.7370465934182993, is more negative than t_value, reject the null hypothesis\n",
    "\n",
    "Note: ChatGPT uses a two-tailed test, which has a t_value=±2.262, at df=10-1=9, both reject the null hypothesis\n",
    "\n",
    "\n",
    "CI1 = -2.4079362312409387\n",
    "\n",
    "CI2 = -0.5920637687590611\n",
    "\n",
    "When schoolchildren are matched for home environment, we are 95 percent confident that the interval between –0.60 and –2.40 covers the reduction in estimated severity of colds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf81bc-4b7a-47a7-b559-50312816c644",
   "metadata": {},
   "source": [
    "#### Progress Check *15.5 Each of the following studies requires a t test for one or more population means. Specify whether the appropriate t test is for one sample, two independent samples, or two related samples, and in the last case, whether it involves repeated measures or matched pairs of different subjects.\n",
    "\n",
    "(a) College students are randomly assigned to receive either behavioral or cognitive therapy. After twenty therapeutic sessions, each student earns a score on a mental health questionnaire. Answer: t test for two independent samples\n",
    "\n",
    "(b) A researcher wishes to determine whether attendance at a day-care center increases the scores of three-year-old children on a motor skill test. Random assignment dictates which twin from each pair of twenty twins attends the day-care center and which twin stays at home. (Such a draconian experiment doubtless would incur great resistance from the parents, not to mention the twins!) Answer: t test for two related samples, matched pairs\n",
    "\n",
    "(c) One hundred college freshmen are randomly assigned to sophomore roommates who have either similar or dissimilar vocational goals. At the end of their first year, the mean GPAs of these two groups are to be analyzed. Answer: t test for two independent samples\n",
    "\n",
    "(d) According to the U.S. Department of Health, the average 16-year-old male can do 23 push-ups. A physical education instructor finds that in his school district, 30 randomly selected 16-year-old males can do an average of 28 pushups. Answer: t test for one sample\n",
    "\n",
    "(e) A child psychologist assigns aggression scores to each of 10 children during two 60-minute observation periods separated by an intervening exposure to a series of violent TV cartoons. Answer: t test for two related samples, repeated measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44ab06-ffad-41a8-a853-eb64953884b9",
   "metadata": {},
   "source": [
    "#### Progress Check *15.6 A random sample of 27 California taxpayers reveals an r of .43 between years of education and annual income. Use t to test the null hypothesis at the .05 level of significance that there is no relationship between educational level and annual income for the population of California taxpayers.\n",
    "\n",
    "#### t RATIO FOR A SINGLE POPULATION CORRELATION COEFFICIENT\n",
    "\n",
    "$t=\\dfrac{r-\\rho_{hyp}}{\\sqrt{\\dfrac{1-r^2}{n-2}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb31f557-b6fa-40f0-87af-b188b1a59236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3814036412717288"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% confidence, at 0.05 significance level\n",
    "import math\n",
    "\n",
    "n = 27\n",
    "r = 0.43\n",
    "\n",
    "t = (r - 0)/(math.sqrt((1-r**2)/(n-2)))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626f613e-3c1d-4337-b551-6ea241bb19cd",
   "metadata": {},
   "source": [
    "#### 15.7 An educational psychologist wants to check the claim that regular physical exercise improves academic achievement. To control for academic aptitude, pairs of college students with similar GPAs are randomly assigned to either a treatment group that attends daily exercise classes or a control group. At the end of the experiment, the following GPAs are reported for the seven pairs of participants:\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{PAIR NUMBER} & \\text{PHYSICAL EXERCISE (X1)} & \\text{NO PHYSICAL EXERCISE (X2)} \\\\\n",
    "\\hline\n",
    "1 & 4.00 & 3.75 \\\\\n",
    "2 & 2.67 & 2.74 \\\\\n",
    "3 & 3.65 & 3.42 \\\\\n",
    "4 & 2.11 & 1.67 \\\\\n",
    "5 & 3.21 & 3.00 \\\\\n",
    "6 & 3.60 & 3.25 \\\\\n",
    "7 & 2.80 & 2.65 \\\\\n",
    "\\end{array}\n",
    "\n",
    "(a) Using t, test the null hypothesis at the .01 level of significance.\n",
    "\n",
    "(b) Specify the p-value for this test result. Answer p < 0.05, from the table with df=6, in between 2.447 and 3.707, two-tailed test\n",
    "\n",
    "(c) If appropriate (because the test result is statistically significant), use Cohen’s d to estimate the effect size.\n",
    "\n",
    "(d) How might this test result be reported in the literature?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fdaebe-1bbc-412b-ac61-db45d4765987",
   "metadata": {},
   "source": [
    "#### DIFFERENCE SCORE (D)\n",
    "$D = X_1-X_2$\n",
    "\n",
    "#### MEAN DIFFERENCE SCORE ($\\overline{D}$)\n",
    "\n",
    "$\\overline{D} = \\dfrac{\\Sigma{D}}{n}$\n",
    "\n",
    "#### Statistical Hypothesis\n",
    "\n",
    "Null Hypotheis: $H_0: \\mu_D \\leq 0$\n",
    "\n",
    "Alternative/Research Hypotheis: $H_1: \\mu_D > 0$\n",
    "\n",
    "#### Two Other Possible Alternative Hypotheses\n",
    "$H_0: \\mu_D < 0$ translates into a one-tailed test with the lower tail critical, and a nondirectional hypothesis\n",
    "\n",
    "$H_0: \\mu_D \\neq 0$ translates into a two-tailed test\n",
    "\n",
    "#### SAMPLING DISTRIBUTION OF $\\overline{D}$\n",
    "\n",
    "$\\mu_{\\overline{D}}=\\mu_{D}$\n",
    "\n",
    "#### Standard error\n",
    "\n",
    "$\\sigma_{\\overline{D}}=\\dfrac{{\\sigma}_D}{\\sqrt{n}}$\n",
    "\n",
    "#### t Test\n",
    "\n",
    "$t = \\dfrac{(sample~mean~difference)-(hypothesized~population~mean~difference)}{estimated~standard~error}$\n",
    "\n",
    "Expressed in symbols, t RATIO FOR TWO POPULATION MEANS (TWO RELATED SAMPLES)\n",
    "\n",
    "$t = \\dfrac{\\overline{D}-\\mu_{D_{hyp}}}{S_\\overline{D}}$\n",
    "\n",
    "which has a t sampling distribution with n – 1 degrees of freedom. $\\overline{D}$ represents the sample mean of the difference scores; $\\mu_{D_{hyp}}$ represents the hypothesized population mean (of zero) for the difference scores; and $S_\\overline{D}$ represents the estimated standard error of $\\overline{D}$\n",
    "\n",
    "### Sample Sums of Squares\n",
    "$SS_D=\\Sigma{D}^2-\\dfrac{(\\Sigma{D})^2}{n}$\n",
    "\n",
    "#### SAMPLE STANDARD DEVIATION, $S_D$\n",
    "\n",
    "$S_D = \\sqrt{\\dfrac{SS_D}{n-1}}$\n",
    "\n",
    "#### ESTIMATED STANDARD ERROR, $S_\\overline{D}$\n",
    "\n",
    "$S_\\overline{D}=\\dfrac{S_D}{\\sqrt{n}}$\n",
    "\n",
    "#### CONFIDENCE INTERVAL FOR μD (TWO RELATED SAMPLES)\n",
    "\n",
    "$\\overline{D} \\pm (t_{conf})(S_{\\overline{D}})$\n",
    "\n",
    "where $\\overline{D}$ represents the sample mean of the difference scores; $t_{conf}$ represents a number (distributed with n – 1 degrees of freedom) from the t tables, which satisfies the confidence specifications; and $S_\\overline{D}$ represents the estimated standard error defined in ESTIMATED STANDARD ERROR, $S_\\overline{D}$\n",
    "\n",
    "$S_\\overline{D}=\\dfrac{S_D}{\\sqrt{n}}$\n",
    "\n",
    "#### STANDARDIZED EFFECT SIZE, COHEN’S d (TWO RELATED SAMPLES)\n",
    "\n",
    "$d=\\dfrac{\\overline{D}}{S_D}$\n",
    "\n",
    "#### Markdown for CALCULATIONS FOR THE t TEST: REPEATED MEASURES (EPO EXPERIMENT)\n",
    "\n",
    "$\\Sigma{D}=1.5599999999999996$\n",
    "\n",
    "$\\Sigma{D^2}=0.503$\n",
    "\n",
    "$\\overline{D}=0.2228571428571428$\n",
    "\n",
    "$SS_D=14.0$\n",
    "\n",
    "$S_D=1.6733200530681511$\n",
    "\n",
    "$S_\\overline{D}=0.6831300510639733$\n",
    "\n",
    "$t=7.319250547113998$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dcd6dd5-bba9-4beb-bdbb-1959dffd6a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_overline = 0.22285714285714286\n",
      "sum_D = 1.5599999999999996\n",
      "sum_of_sq_of_each_D = 0.503\n",
      "SSD = 0.15534285714285728\n",
      "sample_standard_deviation_SD = 0.16090517763725384\n",
      "est_std_error = 0.06081644067012074\n",
      "t_ratio = 3.664422652847441\n",
      "Cohen's d = 1.3850215768665575\n"
     ]
    }
   ],
   "source": [
    "# a) Using t, test the null hypothesis at the .01 level of significance, df=7-1=6, t_value=±3.707\n",
    "X1 = [4.00,2.67,3.65,2.11,3.21,3.60,2.80]\n",
    "X2 = [3.75,2.74,3.42,1.67,3.00,3.25,2.65]\n",
    "# X1 = [12, 5, 11, 11, 9, 18]\n",
    "# X2 = [7, 3, 4, 6, 3, 13]\n",
    "# X1 = [2,5,7,0,3,7,4,5,1,3]\n",
    "# X2 = [3,4,9,3,5,7,6,8,2,5]\n",
    "def t_test_repeated_measures(a,b):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    n = len(a)\n",
    "    X1_mean = statistics.mean(X1)\n",
    "    X2_mean = statistics.mean(X2)\n",
    "    D_overline = X1_mean - X2_mean\n",
    "    print(f'D_overline = {D_overline}')\n",
    "    \n",
    "    D = [X1[n]-X2[n] for n in range(0,len(X1))]\n",
    "    # print(f'D = {D}')\n",
    "\n",
    "    sum_D = sum(D)\n",
    "    print(f'sum_D = {sum_D}')\n",
    "\n",
    "    sq_of_each_D = [d**2 for d in D]\n",
    "    # print(f'sq_of_each_D = {sq_of_each_D}')\n",
    "\n",
    "    sum_of_sq_of_each_D = sum(sq_of_each_D)\n",
    "    print(f'sum_of_sq_of_each_D = {sum_of_sq_of_each_D}')\n",
    "\n",
    "    SSD = sum_of_sq_of_each_D - (sum_D**2/n)\n",
    "    print(f'SSD = {SSD}')\n",
    "\n",
    "    sample_standard_deviation_SD = math.sqrt(SSD/(n-1))\n",
    "    print(f'sample_standard_deviation_SD = {sample_standard_deviation_SD}')\n",
    "\n",
    "    est_std_error = sample_standard_deviation_SD/math.sqrt(n)\n",
    "    print(f'est_std_error = {est_std_error}')\n",
    "\n",
    "    t_ratio = (D_overline-0)/est_std_error\n",
    "    print(f't_ratio = {t_ratio}')\n",
    "\n",
    "    d = D_overline/sample_standard_deviation_SD\n",
    "    print(f\"Cohen's d = {d}\")\n",
    "t_test_repeated_measures(X1,X2)\n",
    "\n",
    "# t_ratio = 3.66442265284744 is less than critical t_value = 3.707, we retain the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5ad0f0-41cd-4910-a048-caeb32bdf866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 3.6644226528474397\n",
      "Critical Value of t: 3.707428021324907\n",
      "P-Value: 0.010523873876434144\n",
      "Is the p-value less than 0.05? True\n",
      "Mean Difference Score: 0.2228571428571428\n",
      "Sample Standard Deviation: 0.16090517763725384\n",
      "Estimated Standard Error: 0.06081644067012074\n",
      "Cohen's d: 1.3850215768665572\n",
      "Should we retain the null hypothesis? True\n"
     ]
    }
   ],
   "source": [
    "# Solution from ChatGPT\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "physical_exercise = np.array([4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80])\n",
    "no_physical_exercise = np.array([3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65])\n",
    "\n",
    "# Paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(physical_exercise, no_physical_exercise)\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(physical_exercise) - 1\n",
    "\n",
    "# Critical value for a two-tailed test at 0.01 significance level\n",
    "alpha = 0.01\n",
    "t_critical = stats.t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Mean difference score\n",
    "mean_difference = np.mean(physical_exercise - no_physical_exercise)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std = np.std(physical_exercise - no_physical_exercise, ddof=1)\n",
    "\n",
    "# Estimated standard error\n",
    "std_error = sample_std / np.sqrt(len(physical_exercise))\n",
    "\n",
    "# Cohen's d for paired samples\n",
    "cohens_d = mean_difference / sample_std\n",
    "\n",
    "# Output results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"Critical Value of t:\", t_critical)\n",
    "print(\"P-Value:\", p_value)\n",
    "print(\"Is the p-value less than 0.05?\", p_value < 0.05)\n",
    "print(\"Mean Difference Score:\", mean_difference)\n",
    "print(\"Sample Standard Deviation:\", sample_std)\n",
    "print(\"Estimated Standard Error:\", std_error)\n",
    "print(\"Cohen's d:\", cohens_d)\n",
    "print(\"Should we retain the null hypothesis?\", p_value > alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38310d1-d98f-432e-a9b6-a40e67b8d7ed",
   "metadata": {},
   "source": [
    "#### 15.8 A school psychologist wishes to determine whether a new antismoking film actually reduces the daily consumption of cigarettes by teenage smokers. The mean daily cigarette consumption is calculated for each of eight teenage smokers during the month before and the month after the film presentation, with the following results:\n",
    "\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{} & \\text{MEAN DAILY-->}&\\text{<--CIGARETTE CONSUMPTION} \\\\\n",
    "\\hline\n",
    "\\text{SMOKER NUMBER} & \\text{BEFORE FILM ($X_1$)} & \\text{AFTER FILM ($X_2$)} \\\\\n",
    "\\hline\n",
    "1 & 28 & 26 \\\\\n",
    "2 & 29 & 27 \\\\\n",
    "3 & 31 & 32 \\\\\n",
    "4 & 44 & 44 \\\\\n",
    "5 & 35 & 35 \\\\\n",
    "6 & 20 & 16 \\\\\n",
    "7 & 50 & 47 \\\\\n",
    "8 & 25 & 23 \\\\\n",
    "\\end{array}\n",
    "\n",
    "(Note: When deciding on the form of the alternative hypothesis, $H_1$, remember that a positive difference score ($D = X_1 − X_2$) reflects a decline in cigarette consumption.)\n",
    "\n",
    "Hypothesis Statement:\n",
    "\n",
    "Null Hypotheis: $H_0: \\mu_D = 0$\n",
    "\n",
    "Alternative/Research Hypotheis: $H_1: \\mu_D \\neq 0$\n",
    "\n",
    "(a) Using t, test the null hypothesis at the .05 level of significance.\n",
    "\n",
    "(b) Specify the p-value for this test result. Answer: According to the t ratio table, the t_ratio=2.5099800796022267, with df=7 is in between values 2.365 and 3.499, which has a p<0.05\n",
    "\n",
    "(c) If appropriate (because the null hypothesis was rejected), construct a 95 percent confidence interval for the true population mean for all difference scores and use Cohen’s d to obtain a standardized estimate of the effect size. Interpret these results.\n",
    "\n",
    "(d) What might be done to improve the design of this experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c09d23-dabf-456b-9638-f76c1494560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_overline = 1.5\n",
      "sum_D = 12\n",
      "sum_of_sq_of_each_D = 38\n",
      "SSD = 20.0\n",
      "sample_standard_deviation_SD = 1.6903085094570331\n",
      "est_std_error = 0.5976143046671968\n",
      "t_ratio = 2.5099800796022267\n",
      "Cohen's d = 0.8874119674649424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5, 0.5976143046671968]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) Using t, test the null hypothesis at the .05 level of significance.\n",
    "# For a two-tailed paired test, df=8-1=7, t_value=±2.365\n",
    "# BEFORE_FILM_X1 = [28,29,31,44,35,20,50,25]\n",
    "# AFTER_FILM_X2 = [26,27,32,44,35,16,47,23]\n",
    "X1 = [28,29,31,44,35,20,50,25]\n",
    "X2 = [26,27,32,44,35,16,47,23]\n",
    "def t_test_repeated_measures(a,b):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    n = len(a)\n",
    "    X1_mean = statistics.mean(X1)\n",
    "    X2_mean = statistics.mean(X2)\n",
    "    D_overline = X1_mean - X2_mean\n",
    "    print(f'D_overline = {D_overline}')\n",
    "    \n",
    "    D = [X1[n]-X2[n] for n in range(0,len(X1))]\n",
    "    # print(f'D = {D}')\n",
    "\n",
    "    sum_D = sum(D)\n",
    "    print(f'sum_D = {sum_D}')\n",
    "\n",
    "    sq_of_each_D = [d**2 for d in D]\n",
    "    # print(f'sq_of_each_D = {sq_of_each_D}')\n",
    "\n",
    "    sum_of_sq_of_each_D = sum(sq_of_each_D)\n",
    "    print(f'sum_of_sq_of_each_D = {sum_of_sq_of_each_D}')\n",
    "\n",
    "    SSD = sum_of_sq_of_each_D - (sum_D**2/n)\n",
    "    print(f'SSD = {SSD}')\n",
    "\n",
    "    sample_standard_deviation_SD = math.sqrt(SSD/(n-1))\n",
    "    print(f'sample_standard_deviation_SD = {sample_standard_deviation_SD}')\n",
    "\n",
    "    est_std_error = sample_standard_deviation_SD/math.sqrt(n)\n",
    "    print(f'est_std_error = {est_std_error}')\n",
    "\n",
    "    t_ratio = (D_overline-0)/est_std_error\n",
    "    print(f't_ratio = {t_ratio}')\n",
    "\n",
    "    d = D_overline/sample_standard_deviation_SD\n",
    "    print(f\"Cohen's d = {d}\")\n",
    "    return [D_overline, est_std_error]\n",
    "t_test_repeated_measures(X1,X2)\n",
    "\n",
    "# We retain the reject the hypothesis because t_ratio = 2.5099800796022267 is greater than t_value=2.365"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de7675-ffbf-4ace-a816-76eb6c7b8c63",
   "metadata": {},
   "source": [
    "#### Solution from ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73876f1d-dec1-4044-89bc-cfd6ceb9b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-Statistic: 2.5099800796022267\n",
      "Critical Value of t: 2.3646242510102993\n",
      "P-Value: 0.040398095491595926\n",
      "Is the p-value less than 0.05? True\n",
      "Mean Difference Score: 1.5\n",
      "Sample Standard Deviation: 1.6903085094570331\n",
      "Estimated Standard Error: 0.5976143046671968\n",
      "Cohen's d: 0.8874119674649424\n",
      "Should we retain the null hypothesis? False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data\n",
    "before_film = np.array([28, 29, 31, 44, 35, 20, 50, 25])\n",
    "after_film = np.array([26, 27, 32, 44, 35, 16, 47, 23])\n",
    "\n",
    "# Paired t-test\n",
    "t_statistic, p_value = stats.ttest_rel(before_film, after_film)\n",
    "\n",
    "# Degrees of freedom\n",
    "df = len(before_film) - 1\n",
    "\n",
    "# Critical value for a two-tailed test at 0.05 significance level\n",
    "alpha = 0.05\n",
    "t_critical = stats.t.ppf(1 - alpha / 2, df)\n",
    "\n",
    "# Mean difference score\n",
    "mean_difference = np.mean(before_film - after_film)\n",
    "\n",
    "# Sample standard deviation\n",
    "sample_std = np.std(before_film - after_film, ddof=1)\n",
    "\n",
    "# Estimated standard error\n",
    "std_error = sample_std / np.sqrt(len(before_film))\n",
    "\n",
    "# Cohen's d for paired samples\n",
    "cohens_d = mean_difference / sample_std\n",
    "\n",
    "# Output results\n",
    "print(\"T-Statistic:\", t_statistic)\n",
    "print(\"Critical Value of t:\", t_critical)\n",
    "print(\"P-Value:\", p_value)\n",
    "print(\"Is the p-value less than 0.05?\", p_value < 0.05)\n",
    "print(\"Mean Difference Score:\", mean_difference)\n",
    "print(\"Sample Standard Deviation:\", sample_std)\n",
    "print(\"Estimated Standard Error:\", std_error)\n",
    "print(\"Cohen's d:\", cohens_d)\n",
    "print(\"Should we retain the null hypothesis?\", p_value > alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5c73cd-b659-41fe-9d5d-60072675fb15",
   "metadata": {},
   "source": [
    "#### CONFIDENCE INTERVAL FOR μD (TWO RELATED SAMPLES)\n",
    "\n",
    "$\\overline{D} \\pm (t_{conf})(S_{\\overline{D}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b4f76e3-0c1c-4979-9cad-f24b0c61518e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI1 = 0.08664216946207959\n",
      "CI2 = 2.9133578305379206\n"
     ]
    }
   ],
   "source": [
    "# (c) If appropriate (because the null hypothesis was rejected), construct a 95 percent confidence interval for the true population mean \n",
    "# for all difference scores and use Cohen’s d to obtain a standardized estimate of the effect size. Interpret these results.\n",
    "\n",
    "CI1 = 1.5 - (2.365*0.5976143046671968)\n",
    "CI2 = 1.5 + (2.365*0.5976143046671968)\n",
    "print(f'CI1 = {CI1}\\nCI2 = {CI2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18858a29-6749-43f0-b03e-ee9f0e81b25e",
   "metadata": {},
   "source": [
    "#### 15.9 A manufacturer of a gas additive claims that it improves gas mileage. A random sample of 30 drivers tests this claim by determining their gas mileage for a full tank of gas that contains the additive (X1) and for a full tank of gas that does not contain the additive (X2). The sample mean difference, D, equals 2.12 miles (in favor of the additive), and the estimated standard error equals 1.50 miles.\n",
    "\n",
    "(a) Using t, test the null hypothesis at the .05 level of significance.\n",
    "\n",
    "(b) Specify the p-value for this result.\n",
    "\n",
    "(c) Are there any special precautions that should be taken with the present experimental design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "584df59c-e3db-4c62-9976-36acc0d37141",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_ratio = 1.4133333333333333\n"
     ]
    }
   ],
   "source": [
    "# a) At 95% confidence level, significance level of 0.05, two-tailed test, df=n-1=30-1=29, t_value=±2.045\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "D_overline = 2.12\n",
    "est_std_error = 1.5\n",
    "t_ratio = (D_overline-0)/est_std_error\n",
    "print(f't_ratio = {t_ratio}')\n",
    "# t_ratio = 1.4133333333333333 is less than the t_value=2.045, we retain the null hypothesis that the additive does not increase the mileage\n",
    "\n",
    "# b) p > 0.05, according to the t values table, t_ratio = 1.4133333333333333, at df=29 is less than t_value=2.045, looking at the left line,\n",
    "# up, it will have to be p > 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d09cc5-9d75-4c71-82f0-6198b8b9d8c0",
   "metadata": {},
   "source": [
    "#### *15.10 In a classic study, which predates the existence of the EPO drug, Melvin Williams of Old Dominion University actually injected extra oxygen-bearing red cells into the subjects’ bloodstream just prior to a treadmill test. Twelve long-distance runners were tested in 5-mile runs on treadmills. Essentially, two running times were obtained for each athlete, once in the treatment or blood-doped condition after the injection of two pints of blood and once in the placebo control or non-blood-doped condition after the injection of a comparable amount of a harmless red saline solution. The presentation of the treatment and control conditions was counterbalanced, with half of the subjects unknowingly receiving the treatment first, then the control, and the other half receiving the conditions in reverse order.\n",
    "\n",
    "#### Since the difference scores, as reported in the New York Times, on May 4, 1980, are calculated by subtracting blood-doped running times from control running times, a positive mean difference signifies that the treatment has a facilitative effect, that is, the athletes’ running times are shorter when blood doped. The 12 athletes had a mean difference running time, $\\overline{D}$, of 51.33 seconds with a standard deviation, $S_D$, of 66.33 seconds.\n",
    "\n",
    "(a) Test the null hypothesis at the .05 level of significance.\n",
    "\n",
    "(b) Specify the p-value for this result.\n",
    "\n",
    "(c) Would you have arrived at the same decision about the null hypothesis if the difference scores had been reversed by subtracting the control times from the blood-doped times?\n",
    "\n",
    "Answer: Yes. Although the appearance of the test results would change (since now negative rather than positive difference scores would support the research hypothesis), H0 still would have been rejected, and the interpretation would have been the same.\n",
    "\n",
    "(d) If appropriate, construct and interpret a 95 percent confidence interval for the true effect of blood doping.\n",
    "\n",
    "(e) Calculate and interpret Cohen’s d for these results.\n",
    "\n",
    "(f) How might this result be reported in the literature?\n",
    "\n",
    "(g) Why is it important to counterbalance the presentation of blood-doped and control conditions?\n",
    "\n",
    "(h) Comment on the wisdom of testing each subject twice—once under the blood-doped condition and once under the control condition—during a single 24-hour period. (Williams actually used much longer intervals in his study.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46c9ce40-2fcd-4e45-81c0-36225d52f702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_ratio = 2.6807226881504738\n",
      "est_std_error = 19.14782167767394\n"
     ]
    }
   ],
   "source": [
    "# (a) Test the null hypothesis at the .05 level of significance.\n",
    "# df=12-1=11, two-tailed test, t_value=±2.201, the book uses a one-tailed upper critical test, t_value=1.796\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "n = 12\n",
    "D_overline = 51.33\n",
    "sample_standard_deviation_SD = 66.33\n",
    "est_std_error = sample_standard_deviation_SD/math.sqrt(n)\n",
    "\n",
    "t_ratio = (D_overline-0)/est_std_error\n",
    "print(f't_ratio = {t_ratio}')\n",
    "print(f'est_std_error = {est_std_error}')\n",
    "# reject the null hypothesis\n",
    "\n",
    "# b) From the Critical values of t table, t_ratio = 2.6807226881504738, df=11, two-tailed test is between 2.201 and 3.106, looking at the\n",
    "# line then up, p<0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "810dda0f-c415-482a-b155-a4c1205126de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI1 = 9.18564448743966\n",
      "CI2 = 93.47435551256034\n"
     ]
    }
   ],
   "source": [
    "# (d) If appropriate, construct and interpret a 95 percent confidence interval for the true effect of blood doping.\n",
    "CI1 = D_overline - (2.201*est_std_error)\n",
    "CI2 = D_overline + (2.201*est_std_error)\n",
    "print(f'CI1 = {CI1}\\nCI2 = {CI2}')\n",
    "\n",
    "# We can claim, with 95 percent confidence, that the interval between 9.16 and 93.50 seconds includes the true effect of blood doping. \n",
    "# Being positive, all of these differences suggest that blood doping has the desired effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c9928c6-4016-4ba2-aaa2-1136be5ab257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's d = 0.7738579828132067\n"
     ]
    }
   ],
   "source": [
    "# (e) Calculate and interpret Cohen’s d for these results.\n",
    "d = D_overline/sample_standard_deviation_SD\n",
    "print(f\"Cohen's d = {d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
