{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c238c914-6d00-4e9b-9dce-e18f827316a2",
   "metadata": {},
   "source": [
    "#### $\\bullet$ F test\n",
    "F Ratio\n",
    "\n",
    "$F=\\dfrac{variability~between~groups}{variability~within~groups}$\n",
    "\n",
    "An F test of the null hypothesis is based on the notion that if the null hypothesis is true, both the numerator and the denominator of the F ratio would tend to be about the same, but if the null hypothesis is false, the numerator would tend to be larger than the denominator.\n",
    "\n",
    "#### If Null Hypothesis Is True\n",
    "\n",
    "$F=\\dfrac{random~error}{random~error}$\n",
    "\n",
    "Except for chance, estimates in both the numerator and the denominator are similar, and generally, F varies about a value of 1.\n",
    "\n",
    "#### If Null Hypothesis Is False\n",
    "\n",
    "$F=\\dfrac{random~error + treatment~effect}{random~error}$\n",
    "\n",
    "When the null hypothesis is false, the presence of a treatment effect tends to cause a chain reaction: The observed differences between group means tend to be large, as does the variability between groups. Accordingly, the numerator term tends to exceed the denominator term, producing an F whose value is larger than 1. When the null hypothesis is false because of a large treatment effect, there is an even more pronounced chain reaction, beginning with very large observed differences between group means and ending with an F whose value tends to be considerably larger than 1.\n",
    "\n",
    "#### $\\bullet$ VARIANCE ESTIMATES\n",
    "\n",
    "Sum of Squares (sum of squared deviations about their mean)\n",
    "\n",
    "$SS=\\Sigma(X-\\overline{X})^2$\n",
    "\n",
    "Sample Variance, $s^2$\n",
    "\n",
    "$s^2=\\dfrac{SS}{n-1}=\\dfrac{SS}{df}$\n",
    "\n",
    "#### Mean Square (MS) - A variance estimate in ANOVA, referred to as a mean square, consists of some sum of squares divided by its degrees of freedom.\n",
    "\n",
    "$MS=\\dfrac{SS}{df}$\n",
    "\n",
    "#### $\\bullet$ Sum of Squares (SS ): Definitional Formulas\n",
    "\n",
    "$SS_{between}$ the sum of squares for variability between groups\n",
    "\n",
    "$SS_{within}$ the sum of squares for variability within groups\n",
    "\n",
    "$SS_{total}$ the sum of squares for the total of these two, equals the sum of the squared deviations of all scores about the grand mean.\n",
    "\n",
    "#### $ * SS_{total}$\n",
    "\n",
    "$SS_{total}=\\Sigma(X-\\overline{X}_{grand})^2$\n",
    "\n",
    "where $X$ represents each score and $\\overline{X}_{grand}$ represents the one overall mean for all scores. Although $SS_{total}$ isn’t directly involved in the calculation of the F ratio, it serves as a valuable computational check.\n",
    "\n",
    "#### $ * SS_{between}$\n",
    "\n",
    "$SS_{between}=n\\Sigma(\\overline{X}_{group}-\\overline{X}_{grand})^2$\n",
    "\n",
    "where $n$ represents the number of scores in each group, $\\overline{X}_{group}$ is the mean for each group, and $\\overline{X}_{grand}$ is the overall mean for all groups. This term contributes to the numerator of the $F$ ratio. The sample size for each group, $n$, in the expression for $SS_{between}$ reflects the fact that the deviation $\\overline{X}_{group}-\\overline{X}_{grand}$ is the same for every score, $n$, in that group.\n",
    "\n",
    "#### $ * SS_{within}$\n",
    "\n",
    "$SS_{within}=\\Sigma(X-\\overline{X}_{group})^2$\n",
    "\n",
    "where $X$ represents each score and $\\overline{X}_{group}$ is the mean for each group. This term contributes to the denominator of the $F$ ratio. Essentially, it requires that we calculate the sum of squares, $SS$, within each group and then add these terms across all groups—in a procedure similar to that used with the two $SS$ terms in the numerator of Formula 14.2 (page 254) for the polled variance estimate, $s^2_p$. Since $SS_{within}$ always reflects only the pooled variability among subjects treated similarly, it can be referred to, more generally, as the sum of squares for random error and symbolized as $SS_{error}$.\n",
    "\n",
    "#### $\\bullet$ Sum of Squares (SS): Computation Formulas\n",
    "\n",
    "$SS=\\Sigma(X-\\overline{X})^2=\\Sigma{X^2}-\\dfrac{(\\Sigma{X})^2}{n}$\n",
    "\n",
    "where the total, ΣX, represents a key component in the conversion from means in the definition formulas to totals in the computation formulas.\n",
    "\n",
    "### $\\bullet$ WORD, DEFINITION, AND COMPUTATION FORMULAS FOR SS TERMS\n",
    "\n",
    "$\\bullet$ For the total sums of squares,\n",
    "\n",
    "$SS_{total}=$ the sum of squared deviations for scores about the grand mean\n",
    "           \n",
    "$=\\Sigma(X-\\overline{X}_{grand})^2$\n",
    "\n",
    "$SS_{total}=\\Sigma{X}^2-\\dfrac{G^2}{N}$, where $G$ is the grand total and $N$ is its sample size\n",
    "\n",
    "$\\bullet$ For the between sum of squares,\n",
    "\n",
    "$SS_{between}=$ the sum of squared deviations for group means about the grand mean\n",
    "\n",
    "$=n\\Sigma(\\overline{X}_{group}-\\overline{X}_{grand})^2$\n",
    "\n",
    "$SS_{between}=\\Sigma\\dfrac{T^2}{n}-\\dfrac{G^2}{N}$, where $T$ is the group total and $n$ is its sample size\n",
    "\n",
    "$\\bullet$ For the within sum of squares,\n",
    "\n",
    "$SS_{within}=$ the sum of squared deviations of scores about their respective\n",
    "group means\n",
    "\n",
    "$=\\Sigma(X-\\overline{X}_{group})^2$\n",
    "\n",
    "$SS_{within}=\\Sigma{X^2}-\\Sigma\\dfrac{T^2}{n}$\n",
    "\n",
    "#### $\\bullet$ REMINDER:\n",
    "\n",
    "$X=$ raw score\n",
    "\n",
    "$T=$ group total\n",
    "\n",
    "$n=$ group sample size\n",
    "\n",
    "$G=$ grand total\n",
    "\n",
    "$N=$ grand (combined) sample size\n",
    "\n",
    "#### $\\bullet$ FORMULAS FOR $df$ TERMS\n",
    "\n",
    "$N$ = number of total scores for all the groups\n",
    "\n",
    "$k$ = number of groups\n",
    "\n",
    "$df_{total}=N-1$, that is, the number of all scores − 1\n",
    "\n",
    "$df_{between}=k-1$, hat is the number of groups − 1\n",
    "\n",
    "$df_{within}=N-k$, that is, the number of all scores − number of groups\n",
    "\n",
    "DEGREES OF FREEDOM (ONE FACTOR)\n",
    "\n",
    "$df_{total}=df_{between}+df_{within}$\n",
    "\n",
    "#### $\\bullet$ MEAN SQUARE BETWEEN GROUPS\n",
    "\n",
    "$MS_{between}=\\dfrac{SS_{between}}{df_{between}}$\n",
    "\n",
    "#### $\\bullet$ F RATIO (ONE FACTOR)\n",
    "\n",
    "$\\bullet$ To determine the critical value of F from the table, we need to look at the level of significance, $df_{between}$, and the $df_{within}$\n",
    "\n",
    "$F=\\dfrac{MS_{between}}{MS_{within}}$\n",
    "\n",
    ".05 LEVEL OF SIGNIFICANCE (LIGHT NUMBERS)\n",
    "\n",
    ".01 LEVEL OF SIGNIFICANCE (DARK NUMBERS)\n",
    "\n",
    "#### $\\bullet$ PROPORTION OF EXPLAINED VARIANCE, η2 (ONE-FACTOR ANOVA)\n",
    "$\\eta^2$ - squared curvilinear correlation coefficient\n",
    "\n",
    "$\\eta^2=\\dfrac{SS_{between}}{SS_{total}}$\n",
    "\n",
    "$\\bullet$ Guidelines for $\\eta^2$\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{$\\eta^2$} & \\text{EFFECT} &\\\\\n",
    "\\hline\n",
    ".01 & small \\\\\n",
    ".09 & medium \\\\\n",
    ".25 & large \\\\\n",
    "\\end{array}\n",
    "\n",
    "#### $\\bullet$ TUKEY’S HSD TEST (honestly significant difference)\n",
    "\n",
    "$HSD=q\\sqrt{\\dfrac{MS_{within}}{n}}$\n",
    "\n",
    "$\\bullet$ Note: $HSD$ assumes equal sample sizes. Otherwise, if sample sizes are not equal and you lack access to an automatically adjusting computer program, such as Minitab, SAS, or SPSS, replace $n$ in $HSD$ equation with the mean of all sample sizes, $\\overline{n}$\n",
    "\n",
    "where:\n",
    "\n",
    "$HSD$ is the positive critical value for any difference between two means\n",
    "\n",
    "$q$ is a value, technically referred to as the Studentized Range Statistic, obtained from Table G in Appendix C, cell intersected by $k$, the number of groups, and $df_{within}=N-k$, the degrees of freedom for within-group (or error) variability in the original ANOVA\n",
    "\n",
    "$MS_{within}$ is the customary mean square for within-group variability for the overall ANOVA\n",
    "\n",
    "$n$ is the sample size in each group\n",
    "\n",
    "#### $\\bullet$ STANDARDIZED EFFECT SIZE, COHEN’S d (ADAPTED FOR ANOVA)\n",
    "\n",
    "$d=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{s^2_p}}=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{MS_{within}}}$\n",
    "\n",
    "### Critical Value of F\n",
    "To read either table, simply find the cell intersected by the column with the degrees of freedom equal to $df_{between}$ and by the row with the degrees of freedom equal to $df_{within}$\n",
    "\n",
    "$row => df_{within}$\n",
    "\n",
    "$column => df_{between}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d448ed3-6485-4e7a-ae5d-5d6f0d0de30a",
   "metadata": {},
   "source": [
    "### Progress Check *16.3 Find the critical values for the following F tests:\n",
    "(a) α = .05, dfbetween = 1, dfwithin = 18\n",
    "\n",
    "(b) α = .01, dfbetween = 3, dfwithin = 56\n",
    "\n",
    "(c) α = .05, dfbetween = 2, dfwithin = 36\n",
    "\n",
    "(d) α = .05, dfbetween = 4, dfwithin = 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e274cac-8e1c-4860-9a94-506b62027392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_critical(df_within,df_between,alpha):\n",
    "    from scipy.stats import f\n",
    "    \n",
    "    critical_value = round(f.ppf(1 - alpha, df_between, df_within),3)\n",
    "    print(f'Critical F value = {critical_value}')\n",
    "\n",
    "f_critical(18,1,0.05)\n",
    "f_critical(56,3,0.01)\n",
    "f_critical(36,2,0.05)\n",
    "f_critical(95,4,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef159ac-02b8-46a0-af21-355e3d2f5bcc",
   "metadata": {},
   "source": [
    "#### $\\bullet$ SAMPLE STATISTICAL REPORT\n",
    "Aggression scores for subjects deprived of sleep for 0 hours $(\\overline{X} = 2, s = 2.00)$, those deprived for 24 hours $(\\overline{X} = 5, s = 1.73)$, and those deprived for 48 hours $(\\overline{X} = 8, s = 2.00)$ differ significantly $[F (2, 6) = 7.36; MSE = 3.67; p < .05; η^2 = .71]$. According to Tukey’s HSD test, however, only the difference of $6$ between mean aggression scores for the 0 and 48 hour groups is significant $(HSD = 4.77, p < .05, d = 3.13)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5892fa17-c85c-492e-8f03-04fb511a90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.2 TWO SOURCES OF VARIABILITY p.294 (Statistics Wiley)\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "Outcome_A = [[3,5,7],[4,8,6],[2,4,6]]\n",
    "Outcome_B = [[0,4,2],[3,6,6],[6,8,10]]\n",
    "\n",
    "mean_each_Outcome_A = [statistics.mean(a) for a in Outcome_A]\n",
    "print(f'mean_each_Outcome_A = {mean_each_Outcome_A}')\n",
    "mean_each_Outcome_B = [statistics.mean(b) for b in Outcome_B]\n",
    "print(f'mean_each_Outcome_B = {mean_each_Outcome_B}')\n",
    "\n",
    "joined_A = []\n",
    "[joined_A.extend(a) for a in Outcome_A]\n",
    "joined_B = []\n",
    "[joined_B.extend(b) for b in Outcome_B]\n",
    "\n",
    "mean_A = statistics.mean(joined_A)\n",
    "mean_B = statistics.mean(joined_B)\n",
    "\n",
    "print(f'mean_A = {mean_A}\\nmean_B = {mean_B}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500ffd7-a5c3-42d3-8506-56e96cc396f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SS_terms_uneven_samples(sample_data,alpha):\n",
    "    import statistics\n",
    "    import math\n",
    "    from scipy.stats import f\n",
    "    \n",
    "    N = 0\n",
    "    k = len(sample_data)\n",
    "    for s in sample_data:\n",
    "        N += len(s)\n",
    "        # n = len(s)\n",
    "    print(f'N = {N}')\n",
    "\n",
    "    list = [len(s) for s in sample_data if len(s)==len(a[0])]\n",
    "    print(f'a = {a}')\n",
    "    print(len(a))\n",
    "\n",
    "    n = []\n",
    "    if len(list) == len(a):\n",
    "        x = len(a[0])\n",
    "        n.append(x)\n",
    "    else:\n",
    "        print('Unequal')\n",
    "        new = []\n",
    "        [new.extend(data) for data in sample_data]\n",
    "        n.append(len(new)/len(sample_data))\n",
    "    print(f'N = {N}\\nn = {n}\\nk = {k}')\n",
    "    \n",
    "    df_between = k-1\n",
    "    df_within = N-k\n",
    "    print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "\n",
    "    squares = []\n",
    "    G_raw = []\n",
    "    SS_between_raw = []\n",
    "    for s in sample_data:\n",
    "        G_raw.append(sum(s))\n",
    "        # print((sum(s)**2)/n[0])\n",
    "        SS_between_raw.append((sum(s)**2)/n[0])\n",
    "\n",
    "        for item in s:\n",
    "            squares.append(item**2)\n",
    "    # print(G_raw)\n",
    "        \n",
    "    G = sum(G_raw)\n",
    "    print(f'G = {G}')\n",
    "\n",
    "    SS_between = sum(SS_between_raw) - (G**2/N)\n",
    "    print(f'SS_between = {SS_between}')\n",
    "\n",
    "    sum_of_squares = sum(squares)\n",
    "\n",
    "    SS_within = sum_of_squares - sum(SS_between_raw)\n",
    "    print(f'SS_within = {SS_within}')\n",
    "\n",
    "    SS_total = sum_of_squares - (G**2/N)\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    accuracy_check = (SS_between + SS_within) == SS_total\n",
    "    print(f'accuracy_check = {accuracy_check}')\n",
    "\n",
    "    MS_within = round(SS_within/df_within,3)\n",
    "    print(f'MS_within = {MS_within}')\n",
    "\n",
    "    MS_between = SS_between/df_between\n",
    "    print(f'MS_between = {MS_between}')\n",
    "\n",
    "    F_critical_value = round(f.ppf(1 - alpha, df_between, df_within),3)\n",
    "    print(f'F_critical_value = {F_critical_value}')\n",
    "    \n",
    "    F_observed = round(MS_between/MS_within,3)\n",
    "    print(f'F_observed = {F_observed}')\n",
    "\n",
    "    if F_observed > F_critical_value:\n",
    "        print(f'F_observed = {F_observed} is GREATER than F_critical_value = {F_critical_value} at {round((1-alpha)*100)}%, therefore we will REJECT the Null hypothesis')\n",
    "    else:\n",
    "        print(f'F_observed = {F_observed} is LESS than F_critical_value = {F_critical_value} at {round((1-alpha)*100)}%, therefore we will RETAIN the Null hypothesis')\n",
    "\n",
    "    return [SS_between,SS_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c9842-6e32-465d-bce5-4352a6c56f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = [0,4,2]\n",
    "X24 = [3,6,6]\n",
    "X48 = [6,8,10]\n",
    "a = [X0,X24,X48]\n",
    "SS_terms_uneven_samples(a,0.05)\n",
    "print(f'==========')\n",
    "# From the Critical Values of F table at .05 significance level, df_within=6(denominator), df_between=2(numerator)\n",
    "# F = 5.14\n",
    "X0 = [3,5,7]\n",
    "X24 = [4,8,6]\n",
    "X48 = [2,4,6]\n",
    "a = [X0,X24,X48]\n",
    "SS_terms_uneven_samples(a,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f2aac-7450-4b05-ad96-50f8c5d076ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "image_path = \"stat_infographic/Statistics_Flowchart_one_factor_ANOVA.png\"\n",
    "Image(filename=image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d215a4fe-0850-47be-aacc-8ff13625298d",
   "metadata": {},
   "source": [
    "### $\\bullet$ Figure 16.4 serves as a reminder about the steps that should be taken whenever you’re using an F test in ANOVA. Only if the F test is significant should you proceed to estimate the overall effect size with $\\eta^2$ and to test for significant mean differences with Tukey’s HSD test. Finally, the effect size for any significant difference between pairs of means can be estimated with Cohen’s d."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0844023-89b3-48a6-bfc1-1f3fa55198de",
   "metadata": {},
   "source": [
    "#### Progress Check *16.4 Find the approximate p-value for the following observed F ratios, where the numbers in parentheses refer to the degrees of freedom in the numerator and denominator, respectively.\n",
    "df_between = numerator\n",
    "\n",
    "df_within = denominator\n",
    "\n",
    "(a) F (2, 11) = 4.56\n",
    "\n",
    "(b) F (1, 13) = 11.25\n",
    "\n",
    "(c) F (3, 20) = 2.92\n",
    "\n",
    "(d) F (2, 29) = 3.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a592ea-21e2-438c-af59-805525ada874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_value_computation(F_observed,df_between,df_within):\n",
    "    from scipy.stats import f\n",
    "    p_value = round(1 - f.cdf(F_observed, df_between, df_within),7)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f'p_value = {p_value} is LESS than {0.05}, therefore the the F observed is SIGNIFICANT')\n",
    "    else:\n",
    "        print(f'p_value = {p_value} is GREATER than {0.05}, therefore the the F observed is INSIGNIFICANT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b576cbe-4fb6-4c76-9260-db0bf4bab3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)\n",
    "F = 4.56\n",
    "df_bet = 2\n",
    "df_with = 11\n",
    "p_value_computation(F,df_bet,df_with)\n",
    "\n",
    "# b)\n",
    "F = 11.25\n",
    "df_bet = 1\n",
    "df_with = 13\n",
    "p_value_computation(F,df_bet,df_with)\n",
    "\n",
    "# c)\n",
    "F = 2.92\n",
    "df_bet = 3\n",
    "df_with = 20\n",
    "p_value_computation(F,df_bet,df_with)\n",
    "\n",
    "# d)\n",
    "F = 3.66\n",
    "df_bet = 2\n",
    "df_with = 29\n",
    "p_value_computation(F,df_bet,df_with)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd57e873-bee4-489c-a8ae-4220b03eab81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function for Calculation of SS Terms\n",
    "def SS_terms(a,b,c,number_of_groups):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    Xtotal = a+b+c\n",
    "    G = sum(Xtotal)\n",
    "    print(f'G = {G}')\n",
    "    squares_of_Xtotal = [m**2 for m in Xtotal]\n",
    "    \n",
    "    N = len(Xtotal)\n",
    "    n = len(a)\n",
    "    k = number_of_groups\n",
    "    total1 = sum(a)\n",
    "    total2 = sum(b)\n",
    "    total3 = sum(c)\n",
    "    df_between = k-1\n",
    "    df_within = N-k\n",
    "    print(f'total1 = {total1}\\ntotal2 = {total2}\\ntotal3 = {total3}')\n",
    "    \n",
    "    SS_between = ((total1**2/n) + (total2**2/n) + (total3**2/n)) - (G**2)/len(Xtotal)\n",
    "    print(f'SS_between = {SS_between}')\n",
    "\n",
    "    SS_within = sum(squares_of_Xtotal) - ((total1**2/n) + (total2**2/n) + (total3**2/n))\n",
    "    print(f'SS_within = {SS_within}')\n",
    "\n",
    "    SS_total = sum(squares_of_Xtotal) - (G**2)/len(Xtotal)\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    accuracy_check = (SS_between + SS_within) == SS_total\n",
    "    print(f'accuracy_check = {accuracy_check}')\n",
    "\n",
    "    MS_between = SS_between/df_between\n",
    "    print(f'MS_between = {MS_between}')\n",
    "\n",
    "    MS_within = SS_within/df_within\n",
    "    print(f'MS_within = {MS_within}')\n",
    "\n",
    "    print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "    F = MS_between/MS_within\n",
    "    print(f'F = {F}')\n",
    "\n",
    "# X1_0 = [1,0,0,2,3,4,2,1]\n",
    "# X2_24 = [2,1,2,4,4,6,3,3]\n",
    "# X3_48 = [7,1,6,9,10,12,8,7]\n",
    "\n",
    "X1_0 = [0,4,2]\n",
    "X2_24 = [3,6,6]\n",
    "X3_48 = [6,8,10]\n",
    "SS_terms(X1_0,X2_24,X3_48,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfffba2-eb0d-459e-b64c-a82cfcc8d88b",
   "metadata": {},
   "source": [
    "#### Progress Check *16.5 A psychologist tests whether a series of workshops on assertive training increases eye contacts initiated by shy college students in controlled interactions with strangers. A total of 32 subjects are randomly assigned, 8 to a group, to attend either zero, one, two, or three workshop sessions. The results, expressed as the number of eye contacts during a standard observation period, are shown in the following chart. (Also shown for your computational convenience are the values for the sum of squares, group totals, and the grand total.)\n",
    "\n",
    "\n",
    "EYE CONTACTS AS A FUNCTION OF NUMBER OF SESSIONS\n",
    "\\begin{array}{ccc}\n",
    "\\text{ZERO} & \\text{ONE} & \\text{TWO} & \\text{THREE} \\\\\n",
    "\\hline\n",
    "1 & 2 & 4 & 7\\\\\n",
    "0 & 1 & 2 & 1 \\\\\n",
    "0 & 2 & 3 & 6 \\\\\n",
    "2 & 4 & 6 & 9 \\\\\n",
    "3 & 4 & 7 & 10 \\\\\n",
    "4 & 6 & 8 & 12 \\\\\n",
    "2 & 3 & 5 & 8 \\\\\n",
    "1 & 3 & 5 & 7 \\\\\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "(a) Test the null hypothesis at the .05 level of significance. (Use computation formulas for various sums of squares.)\n",
    "\n",
    "(b) Summarize the results with an ANOVA table. Save these results for subsequent questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543c196-4fc5-47d9-a146-2ca011233a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function for SS_terms_prog: Progress Check *16.5\n",
    "def Anova(sample_data,alpha):\n",
    "    from scipy.stats import f\n",
    "    import statistics\n",
    "    from statsmodels.stats.libqsturng import qsturng\n",
    "\n",
    "    N = 0\n",
    "    k = len(sample_data)\n",
    "    for s in sample_data:\n",
    "        N += len(s)\n",
    "        n = len(s)\n",
    "    print(f'N = {N}\\nn = {n}\\nk = {k}')\n",
    "    \n",
    "    df_between = k-1\n",
    "    df_within = N-k\n",
    "    print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "\n",
    "    squares = []\n",
    "    G_raw = []\n",
    "    SS_between_raw = []\n",
    "    for s in sample_data:\n",
    "        G_raw.append(sum(s))\n",
    "        SS_between_raw.append((sum(s)**2)/n)\n",
    "\n",
    "        for item in s:\n",
    "            squares.append(item**2)\n",
    "        \n",
    "    G = sum(G_raw)\n",
    "    print(f'G = {G}')\n",
    "\n",
    "    SS_between = round(sum(SS_between_raw) - (G**2/N),3)\n",
    "    print(f'SS_between = {SS_between}')\n",
    "\n",
    "    sum_of_squares = sum(squares)\n",
    "\n",
    "    SS_within = round(sum_of_squares - sum(SS_between_raw),3)\n",
    "    print(f'SS_within = {SS_within}')\n",
    "\n",
    "    SS_total = sum_of_squares - (G**2/N)\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    accuracy_check = (SS_between + SS_within) == SS_total\n",
    "    print(f'accuracy_check = {accuracy_check}')\n",
    "\n",
    "    MS_within = round(SS_within/df_within,3)\n",
    "    print(f'MS_within = {MS_within}')\n",
    "\n",
    "    MS_between = round(SS_between/df_between,3)\n",
    "    print(f'MS_between = {MS_between}')\n",
    "\n",
    "    SS_total = SS_within + SS_between\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    F_critical_value = round(f.ppf(1 - alpha, df_between, df_within),3)\n",
    "    print(f'F_critical_value = {F_critical_value}')\n",
    "\n",
    "    F_observed = round(MS_between/MS_within,3)\n",
    "    print(f'F_observed = {F_observed}')\n",
    "\n",
    "    proportion_of_explained_variance = round(SS_between/SS_total,3)\n",
    "    print(f'proportion_of_explained_variance = {proportion_of_explained_variance}')\n",
    "\n",
    "    q = round(qsturng(1-alpha, k, df_within),3)\n",
    "    print(f'q = {q}')\n",
    "\n",
    "    Tukeys_HSD_test = round(q*((MS_within/n)**0.5),3)\n",
    "    print(f'Tukeys_HSD_test = {Tukeys_HSD_test}')\n",
    "\n",
    "    means = [round(statistics.mean(data),3) for data in sample_data]\n",
    "    print(f'means = {means}')\n",
    "\n",
    "    max_mean = max(means)\n",
    "    min_mean = min(means)\n",
    "    \n",
    "    Cohens_d = round((max_mean-min_mean)/MS_within**0.5,3)\n",
    "    print(f'Cohens_d = {Cohens_d}')\n",
    "\n",
    "    print(f'SS_between_raw = {SS_between_raw}')\n",
    "\n",
    "    return [SS_between,SS_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2afd23f-bfae-4ca1-be21-cdad6837f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [1,0,0,2,3,4,2,1]\n",
    "one = [2,1,2,4,4,6,3,3]\n",
    "two = [4,2,3,6,7,8,5,5]\n",
    "three = [7,1,6,9,10,12,8,7]\n",
    "a = [zero,one,two,three]\n",
    "Anova(a,0.05)\n",
    "print('==========')\n",
    "X0 = [3,5,7]\n",
    "X24 = [4,8,6]\n",
    "X48 = [2,4,6]\n",
    "b = [X0,X24,X48]\n",
    "Anova(b,0.05)\n",
    "print('==========')\n",
    "X1_0 = [0,4,2]\n",
    "X2_24 = [3,6,6]\n",
    "X3_48 = [6,8,10]\n",
    "c = [X1_0,X2_24,X3_48]\n",
    "Anova(c,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b8f698-a564-4452-8813-f040746a6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Anova_pvalue_HSD(sample_data,alpha):\n",
    "    from scipy.stats import f\n",
    "    import statistics\n",
    "    from statsmodels.stats.libqsturng import qsturng\n",
    "    import statistics,math,numpy\n",
    "    \n",
    "    joined_samples = numpy.concatenate(sample_data)\n",
    "    EX_sq = [item**2 for item in joined_samples]\n",
    "    total_EX_sq = sum(EX_sq)\n",
    "    print(f'total_EX_sq = {total_EX_sq}')\n",
    "\n",
    "    N = 0\n",
    "    k = len(sample_data)\n",
    "    for s in sample_data:\n",
    "        N += len(s)\n",
    "        n = len(s)\n",
    "    print(f'N = {N}\\nn = {n}\\nk = {k}')\n",
    "    \n",
    "    df_between = k-1\n",
    "    df_within = N-k\n",
    "    print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "\n",
    "    squares = []\n",
    "    G_raw = []\n",
    "    SS_between_raw = []\n",
    "    for s in sample_data:\n",
    "        G_raw.append(sum(s))\n",
    "        SS_between_raw.append((sum(s)**2)/n)\n",
    "\n",
    "        for item in s:\n",
    "            squares.append(item**2)\n",
    "        \n",
    "    G = sum(G_raw)\n",
    "    print(f'G = {G}')\n",
    "\n",
    "    SS_between = round(sum(SS_between_raw) - (G**2/N),3)\n",
    "    print(f'SS_between = {SS_between}')\n",
    "\n",
    "    sum_of_squares = sum(squares)\n",
    "\n",
    "    SS_within = round(sum_of_squares - sum(SS_between_raw),3)\n",
    "    print(f'SS_within = {SS_within}')\n",
    "\n",
    "    SS_total = round(sum_of_squares - (G**2/N),3)\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    accuracy_check = (SS_between + SS_within) == SS_total\n",
    "    print(f'accuracy_check = {accuracy_check}')\n",
    "\n",
    "    MS_within = round(SS_within/df_within,3)\n",
    "    print(f'MS_within = {MS_within}')\n",
    "\n",
    "    MS_between = round(SS_between/df_between,3)\n",
    "    print(f'MS_between = {MS_between}')\n",
    "\n",
    "    SS_total = SS_within + SS_between\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    F_critical_value = round(f.ppf(1 - alpha, df_between, df_within),3)\n",
    "    print(f'F_critical_value = {F_critical_value}')\n",
    "\n",
    "    F_observed = round(MS_between/MS_within,3)\n",
    "    print(f'F_observed = {F_observed}')\n",
    "\n",
    "    if F_observed >= F_critical_value:\n",
    "        print(f'F_observed = {F_observed} >= {F_critical_value}, therefore we will REJECT the Null Hypothesis')\n",
    "    else:\n",
    "        print(f'F_observed = {F_observed} < {F_critical_value}, therefore we will RETAIN the Null Hypothesis')\n",
    "\n",
    "    p_value = round(1 - f.cdf(F_observed, df_between, df_within),7)\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(f'p_value = {p_value} is LESS than {0.05}, therefore the F observed is SIGNIFICANT')\n",
    "        proportion_of_explained_variance = round(SS_between/SS_total,3)\n",
    "        print(f'proportion_of_explained_variance = {proportion_of_explained_variance}')\n",
    "        q = round(qsturng(1-alpha, k, df_within),3)\n",
    "        print(f'q = {q}')\n",
    "\n",
    "        Tukeys_HSD_test = round(q*((MS_within/n)**0.5),3)\n",
    "        print(f'Tukeys_HSD_test = {Tukeys_HSD_test}')\n",
    "\n",
    "        means = [round(statistics.mean(data),3) for data in sample_data]\n",
    "        print(f'means = {means}')\n",
    "\n",
    "        max_mean = max(means)\n",
    "        min_mean = min(means)\n",
    "    \n",
    "        Cohens_d = round((max_mean-min_mean)/MS_within**0.5,3)\n",
    "        print(f'Cohens_d = {Cohens_d}')\n",
    "    \n",
    "    else:\n",
    "        print(f'p_value = {p_value} is GREATER than {0.05}, therefore the F observed is INSIGNIFICANT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf588d26-0c3e-4051-847c-11e9b1453126",
   "metadata": {},
   "outputs": [],
   "source": [
    "group1_data = [1, 2, 3, 4, 5]\n",
    "group2_data = [2, 3, 4, 5, 6]\n",
    "group3_data = [3, 4, 5, 6, 7]\n",
    "data_group = group1_data,group2_data,group3_data\n",
    "Anova_pvalue_HSD(data_group,0.05)\n",
    "print('==========')\n",
    "zero = [1,0,0,2,3,4,2,1]\n",
    "one = [2,1,2,4,4,6,3,3]\n",
    "two = [4,2,3,6,7,8,5,5]\n",
    "three = [7,1,6,9,10,12,8,7]\n",
    "a = [zero,one,two,three]\n",
    "Anova_pvalue_HSD(a,0.05)\n",
    "print('==========')\n",
    "X0 = [3,5,7]\n",
    "X24 = [4,8,6]\n",
    "X48 = [2,4,6]\n",
    "b = [X0,X24,X48]\n",
    "Anova_pvalue_HSD(b,0.05)\n",
    "print('==========')\n",
    "X1_0 = [0,4,2]\n",
    "X2_24 = [3,6,6]\n",
    "X3_48 = [6,8,10]\n",
    "c = [X1_0,X2_24,X3_48]\n",
    "Anova_pvalue_HSD(c,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb65f133-d87d-4210-ac18-90390619997f",
   "metadata": {},
   "source": [
    "#### Progress Check *16.6 Given the rejection of the null hypothesis in Question 16.5, estimate the effect size with η2.\n",
    "$\\eta^2=\\dfrac{SS_{between}}{SS_{total}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5832efab-470e-4f37-b3c7-3037fcf7e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_between = Anova(a,0.05)[0]\n",
    "SS_total = Anova(a,0.05)[1]\n",
    "eta_squared = SS_between/SS_total\n",
    "print(f'SS_between = {SS_between}\\nSS_total = {SS_total}')\n",
    "print(f'eta_squared = {eta_squared}, a large effect, according to the guidelines.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57cc869-1ad0-42bf-8476-afb4af8c159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) Progress Check *16.5\n",
    "def SS_terms(a,b,c,d,number_of_groups):\n",
    "    import statistics\n",
    "    import math\n",
    "\n",
    "    Xtotal = a+b+c+d\n",
    "    G = sum(Xtotal)\n",
    "    print(f'G = {G}')\n",
    "    squares_of_Xtotal = [m**2 for m in Xtotal]\n",
    "    \n",
    "    N = len(Xtotal)\n",
    "    n = len(a)\n",
    "    k = number_of_groups\n",
    "    total1 = sum(a)\n",
    "    total2 = sum(b)\n",
    "    total3 = sum(c)\n",
    "    total4 = sum(d)\n",
    "    df_between = k-1\n",
    "    df_within = N-k\n",
    "    print(f'total1 = {total1}\\ntotal2 = {total2}\\ntotal3 = {total3}\\ntotal4 = {total4}')\n",
    "    \n",
    "    SS_between = ((total1**2/n) + (total2**2/n) + (total3**2/n) + (total4**2/n)) - (G**2)/len(Xtotal)\n",
    "    print(f'SS_between = {SS_between}')\n",
    "\n",
    "    SS_within = sum(squares_of_Xtotal) - ((total1**2/n) + (total2**2/n) + (total3**2/n) + (total4**2/n))\n",
    "    print(f'SS_within = {SS_within}')\n",
    "\n",
    "    SS_total = sum(squares_of_Xtotal) - (G**2)/len(Xtotal)\n",
    "    print(f'SS_total = {SS_total}')\n",
    "\n",
    "    accuracy_check = (SS_between + SS_within) == SS_total\n",
    "    print(f'accuracy_check = {accuracy_check}')\n",
    "\n",
    "    MS_between = SS_between/df_between\n",
    "    print(f'MS_between = {MS_between}')\n",
    "\n",
    "    MS_within = SS_within/df_within\n",
    "    print(f'MS_within = {MS_within}')\n",
    "\n",
    "    print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "    F = MS_between/MS_within\n",
    "    print(f'F = {F}')\n",
    "\n",
    "    print(len(Xtotal))\n",
    "    print((total1**2/n) + (total2**2/n) + (total3**2/n) + (total4**2/n))\n",
    "\n",
    "    print(sum(squares_of_Xtotal))\n",
    "    print((total1**2/n) + (total2**2/n) + (total3**2/n) + (total4**2/n))\n",
    "\n",
    "X0 = [1,0,0,2,3,4,2,1]\n",
    "X1 = [2,1,2,4,4,6,3,3]\n",
    "X2 = [4,2,3,6,7,8,5,5]\n",
    "X3 = [7,1,6,9,10,12,8,7]\n",
    "SS_terms(X0,X1,X2,X3,4)\n",
    "# At .05 significance level, df_within = 28, df_between = 3, reject Null hypothesis because F = 10.836158192090394 is greater than F = 2.95\n",
    "print('============')\n",
    "samples = X0,X1,X2,X3\n",
    "Anova(samples,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795cc1a-f7e2-4277-a02c-f65ef550eee3",
   "metadata": {},
   "source": [
    "#### Progress Check *16.7 Given the rejection of the null hypothesis in Question 16.5, Tukey’s HSD test can be used to identify pairs of population means that differ. Using the .05 level of significance, calculate the critical value for HSD and use it to evaluate the statistical significance of each possible mean difference. Use the matrix shown in Table 16.8 as a model. The various sample means are $\\overline{X}_0 = 1.63$, $\\overline{X}_1 = 3.13$, $\\overline{X}_2 = 5.00$, and $\\overline{X}_3 = 7.50$.\n",
    "\\begin{array}{ccc}\n",
    "\\text{} & \\overline{X}_0=1.63 & \\overline{X}_1=3.13 & \\overline{X}_2=5.00 & \\overline{X}_3=7.50 \\\\\n",
    "\\hline\n",
    "\\overline{X}_0=1.63 & - & 1.5 & 3.37 & 5.87 \\\\\n",
    "\\overline{X}_1=3.13 & - & - & 1.87 & 4.37 \\\\\n",
    "\\overline{X}_2=5.00 & - & - & - & 2.5 \\\\\n",
    "\\overline{X}_3=7.50 & - & - & - & -\\\\\n",
    "\\end{array}\n",
    "\n",
    "(a) Estimate the standardized effect size for any significant pair of mean differences with Cohen’s d.\n",
    "\n",
    "(b) Interpret the results of your analysis.\n",
    "\n",
    "$HSD=q\\sqrt{\\dfrac{MS_{within}}{n}}$\n",
    "\n",
    "$q$ is a value, technically referred to as the Studentized Range Statistic, obtained from Table G in Appendix C, cell intersected by $k$, the number of groups, and $df_{within}=N-k$, the degrees of freedom for within-group (or error) variability in the original ANOVA\n",
    "\n",
    "$d=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{s^2_p}}=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{MS_{within}}}$\n",
    "\n",
    "N = 32\n",
    "\n",
    "n = 8\n",
    "\n",
    "k = 4\n",
    "\n",
    "df_between = 3\n",
    "\n",
    "df_within = 28\n",
    "\n",
    "MS_within = 4.741071428571429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab301510-ebb4-4bb1-809b-789cd62d8c3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (a) Estimate the standardized effect size for any significant pair of mean differences with Cohen’s d.\n",
    "import math\n",
    "N = 32\n",
    "k = 4\n",
    "n = 8\n",
    "df_within = N-k\n",
    "alpha = 0.5\n",
    "print(f'df_within = {df_within}')\n",
    "MS_within = 4.741071428571429\n",
    "# From the Table Ga CRITICAL VALUES OF q FOR TUKEY’S HSD TEST at .05 significance level, k=4, df_within=28, between 24 and 30, \n",
    "# must use lower value which is 24\n",
    "q = 3.9\n",
    "\n",
    "hsd = q*math.sqrt(MS_within/n)\n",
    "print(f'HSD = {hsd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e131315-7502-4eff-bb90-a19b7f42991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alph = 0.05\n",
    "num_groups = 2\n",
    "row = 6\n",
    "\n",
    "def q(df_within,k,alpha):\n",
    "    from statsmodels.stats.libqsturng import qsturng\n",
    "    q = qsturng(1-alpha, k, df_within)\n",
    "    print(q)\n",
    "q(row,num_groups,alph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fefb18-ce33-4235-a99e-dcb4eeb48134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# b) Choose the 3 largest differences: 5.87, 4.37, 3.37\n",
    "import math\n",
    "MS_within = 4.741071428571429\n",
    "d1 = 5.87/math.sqrt(MS_within)\n",
    "d2 = 4.37/math.sqrt(MS_within)\n",
    "d3 = 3.37/math.sqrt(MS_within)\n",
    "\n",
    "print(f'd1 = {d1}\\nd2 = {d2}\\nd3 = {d3}\\n')\n",
    "\n",
    "# Students who attend either two or three workshop sessions initiate, on average, more eye contacts than those who attend zero sessions. \n",
    "# Furthermore, those who attend three sessions initiate, on average, more eye contacts than those who attend one session. \n",
    "# All three significant differences had large effect sizes, with d values ranging from 1.55 to 2.69."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed4ff0-9662-4784-b607-fab10e098d86",
   "metadata": {},
   "source": [
    "### $\\bullet$ ANALYSIS OF VARIANCE (ONE FACTOR)\n",
    "Each variance estimate or mean square $(MS)$ is found by dividing the appropriate sum of squares $(SS)$ term by its degrees of freedom $(df)$. Once a value of F has been obtained, it’s compared with a critical $F$ from the table for the $F$ distribution. If the observed $F$ equals or is larger than the critical $F$, the null hypothesis is rejected. Otherwise, for all smaller observed values of $F$, the null hypothesis is retained. Whenever $F$ is statistically significant, use $η^2$ to estimate effect size. Rejection of the overall null hypothesis indicates only that not all population means are equal. To pinpoint differences between specific pairs of population means that contribute to the rejection of the overall null hypothesis, use Tukey’s HSD test. This test ensures that the cumulative probability of a type I error never exceeds the specified level of significance. When the HSD test identifies a significant difference, use Cohen’s d to estimate effect size. F tests in ANOVA assume that all underlying populations are normally distributed, with equal variances. Ordinarily, you need not be too concerned about violations of these assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa34c4e3-6eb0-4c6b-b5a9-3cb27603f56c",
   "metadata": {},
   "source": [
    "#### 16.9 Given the aggression scores below for Outcome A of the sleep deprivation experiment, verify that, as suggested earlier, these mean differences shouldn’t be taken seriously by testing the null hypothesis at the .05 level of significance. Use the computation formulas for the various sums of squares and summarize results with an ANOVA table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac33392-d824-4a67-9da6-2f3a14b5206e",
   "metadata": {},
   "source": [
    "#### *16.10 Another psychologist conducts a sleep deprivation experiment. For reasons beyond his control, unequal numbers of subjects occupy the different groups. (Therefore, when calculating $\\Sigma\\dfrac{T^2}{n}$ , in $SS_{between}$ and $SS_{within}$, you must adjust the denominator term, $n$, to reflect the unequal numbers of subjects in the group totals.)\n",
    "(a) Summarize the results with an ANOVA table. You need not do a step-by-step hypothesis test procedure.\n",
    "\n",
    "(b) If appropriate, estimate the effect size with $η^2$.\n",
    "\n",
    "(c) If appropriate, use Tukey’s HSD test (with $\\overline{n} = 4$ for the sample size, $n$) to identify pairs of means that contribute to the significant $F$, given that $\\overline{X}_0 = 2.60$, $\\overline{X}_{24} = 5.33$, and $\\overline{X}_{48} = 9.50$.\n",
    "\n",
    "(d) If appropriate, estimate effect sizes with Cohen’s d.\n",
    "\n",
    "(e) Indicate how all of the above results would be reported in the literature, given sample standard deviations of $s_0 = 2.07$, $s_{24} = 1.53$, and $s_{48} = 2.08$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642033a-918a-49f0-a7f8-5e5e4edca2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SS_terms_ANOVA(the_data):\n",
    "    import statistics,math,numpy\n",
    "    \n",
    "    joined_samples = numpy.concatenate(the_data)\n",
    "    N = len(joined_samples)\n",
    "    G = sum(joined_samples)\n",
    "    print(f'joined_samples = {joined_samples}')\n",
    "    print(f'N = {N}')\n",
    "    print(f'G = {G}')\n",
    "    \n",
    "\n",
    "    k = len(the_data)\n",
    "    print(f'k = {k}')\n",
    "    \n",
    "    n_uneven = []\n",
    "    n = 0\n",
    "    # for equal number of samples\n",
    "    if all(len(item) == len(the_data[0]) for item in the_data):\n",
    "        n = len(the_data[0])\n",
    "\n",
    "        df_between = k-1\n",
    "        df_within = N-k\n",
    "        print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "        \n",
    "        Tsq_over_n = [sum(list)**2/n for list in the_data]\n",
    "        print(f'Tsq_over_n = {Tsq_over_n}')\n",
    "\n",
    "        total_Tsq_over_n = sum(Tsq_over_n)\n",
    "        print(f'total_Tsq_over_n = {total_Tsq_over_n}')\n",
    "\n",
    "        Gsq_over_N = G**2/N\n",
    "        print(f'Gsq_over_N = {Gsq_over_N}')\n",
    "\n",
    "        SS_between = sum(Tsq_over_n) - Gsq_over_N\n",
    "        print(f'SS_between = {SS_between}')\n",
    "\n",
    "        EX_sq = [item**2 for item in joined_samples]\n",
    "        print(f'EX_sq = {EX_sq}')\n",
    "\n",
    "        total_EX_sq = sum(EX_sq)\n",
    "        print(f'total_EX_sq = {total_EX_sq}')\n",
    "\n",
    "        SS_within = total_EX_sq - total_Tsq_over_n\n",
    "        print(f'SS_within = {SS_within}')\n",
    "\n",
    "        MS_between = SS_between/df_between\n",
    "        print(f'MS_between = {MS_between}')\n",
    "        \n",
    "        MS_within = SS_within/df_within\n",
    "        print(f'MS_within = {MS_within}')\n",
    "\n",
    "        SS_total = total_EX_sq - Gsq_over_N\n",
    "        print(f'SS_total = {SS_total}')\n",
    "\n",
    "        F_ratio = MS_between/MS_within\n",
    "        print(f'F_ratio = {F_ratio}')\n",
    "\n",
    "        proportion_of_explained_variance = SS_between/SS_total\n",
    "        print(f'proportion_of_explained_variance = {proportion_of_explained_variance}')\n",
    "        \n",
    "        print(f'n = {n}')\n",
    "        print(f'n_uneven = {n_uneven}')\n",
    "\n",
    "    # for unequal number of samples\n",
    "    else:\n",
    "        for item in the_data:\n",
    "            n_uneven.append(len(item))\n",
    "\n",
    "        df_between = k-1\n",
    "        df_within = N-k\n",
    "        print(f'df_between = {df_between}\\ndf_within = {df_within}')\n",
    "\n",
    "        T = [sum(list) for list in the_data]\n",
    "        print(f'T = {T}')\n",
    "\n",
    "        T_sq_ns = [(T[n]**2/n_uneven[n]) for n in range(0, len(T))]\n",
    "        print(f'T_sq_ns = {T_sq_ns}')\n",
    "\n",
    "        G = sum(T)\n",
    "        print(f'G = {G}')\n",
    "\n",
    "        G_sq_over_N = G**2/N\n",
    "        print(f'G_sq_over_N = {G_sq_over_N}')\n",
    "\n",
    "        SS_between = sum(T_sq_ns) - G_sq_over_N\n",
    "        print(f'SS_between = {SS_between}')\n",
    "\n",
    "        EX_sq = [item**2 for item in joined_samples]\n",
    "        print(f'EX_sq = {EX_sq}')\n",
    "\n",
    "        total_EX_sq = sum(EX_sq)\n",
    "        print(f'total_EX_sq = {total_EX_sq}')\n",
    "\n",
    "        SS_within = total_EX_sq - sum(T_sq_ns)\n",
    "        print(f'SS_within = {SS_within}')\n",
    "\n",
    "        SS_total = SS_between + SS_within\n",
    "        print(f'SS_total = {SS_total}')\n",
    "\n",
    "        MS_between = SS_between/df_between\n",
    "        print(f'MS_between = {MS_between}')\n",
    "\n",
    "        MS_within = SS_within/df_within\n",
    "        print(f'MS_within = {MS_within}')\n",
    "\n",
    "        F_ratio = MS_between/MS_within\n",
    "        print(f'F_ratio = {F_ratio}')\n",
    "\n",
    "        proportion_of_explained_variance = SS_between/SS_total\n",
    "        print(f'proportion_of_explained_variance = {proportion_of_explained_variance}')\n",
    "        \n",
    "        print(f'n = {n}')\n",
    "        print(f'n_uneven = {n_uneven}')    \n",
    "\n",
    "print('\\n16.10')\n",
    "print(f'Sample3')\n",
    "X0 = [1,3,6,2,1]\n",
    "X24 = [4,7,5]\n",
    "X48 = [7,12,10,9]\n",
    "a = [X0,X24,X48]\n",
    "SS_terms_ANOVA(a)\n",
    "print('At .05 significance level, df_between = 2, df_within = 9, F = 3.86, observed F_ratio = 13.687141491395792, reject the null hypothesis')\n",
    "\n",
    "print('\\n')\n",
    "print('Sample0')\n",
    "X0 = [0,4,2]\n",
    "X24 = [3,6,6]\n",
    "X48 = [6,8,10]\n",
    "a = [X0,X24,X48]\n",
    "SS_terms_ANOVA(a)\n",
    "print(f'At .05 significance level, df_between = 2, df_within = 6, F = 5.14, observed F_ratio = 7.363636363636364, reject the null hypothesis')\n",
    "\n",
    "print('\\n#16.9') \n",
    "print(f'Sample1')\n",
    "X0 = [3,5,7]\n",
    "X24 = [4,8,6]\n",
    "X48 = [2,4,6]\n",
    "a = [X0,X24,X48]\n",
    "SS_terms_ANOVA(a)\n",
    "print(f'At .05 significance level, df_between = 2, df_within = 6, F = 5.14, observed F_ratio = 0.75, retain the null hypothesis')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Sample2')\n",
    "zero = [1,0,0,2,3,4,2,1]\n",
    "one = [2,1,2,4,4,6,3,3]\n",
    "two = [4,2,3,6,7,8,5,5]\n",
    "three = [7,1,6,9,10,12,8,7]\n",
    "a = [zero,one,two,three]\n",
    "SS_terms_ANOVA(a)\n",
    "print('At .05 significance level, df_within = 28, df_between = 3, reject Null hypothesis because F_ratio = 10.836158192090394 is greater than F = 2.95')\n",
    "\n",
    "print('\\n')\n",
    "print('TRIAL')\n",
    "X0 = [1,3,6,2,1]\n",
    "X24 = [4,7,5]\n",
    "X48 = [7,12,10,9]\n",
    "X44 = [4,9,10,15,4]\n",
    "a = [X0,X24,X48,X44]\n",
    "SS_terms_ANOVA(a)\n",
    "print('At .05 significance level, df_within = 13, df_between = 3, reject Null hypothesis because F_ratio = 4.8380420463576925 is greater than F = 3.41')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416a50c-e0f8-4b6a-b756-da2cb046b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n16.10')\n",
    "print(f'Sample3')\n",
    "X0 = [1,3,6,2,1]\n",
    "X24 = [4,7,5]\n",
    "X48 = [7,12,10,9]\n",
    "a = [X0,X24,X48]\n",
    "Anova_pvalue_HSD(a,0.05)\n",
    "print('At .05 significance level, df_between = 2, df_within = 9, F = 3.86, observed F_ratio = 13.687141491395792, reject the null hypothesis')\n",
    "\n",
    "print('\\n')\n",
    "print('Sample0')\n",
    "X0 = [0,4,2]\n",
    "X24 = [3,6,6]\n",
    "X48 = [6,8,10]\n",
    "a = [X0,X24,X48]\n",
    "Anova_pvalue_HSD(a,0.05)\n",
    "print(f'At .05 significance level, df_between = 2, df_within = 6, F = 5.14, observed F_ratio = 7.363636363636364, reject the null hypothesis')\n",
    "\n",
    "print('\\n#16.9') \n",
    "print(f'Sample1')\n",
    "X0 = [3,5,7]\n",
    "X24 = [4,8,6]\n",
    "X48 = [2,4,6]\n",
    "a = [X0,X24,X48]\n",
    "Anova_pvalue_HSD(a,0.05)\n",
    "print(f'At .05 significance level, df_between = 2, df_within = 6, F = 5.14, observed F_ratio = 0.75, retain the null hypothesis')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Sample2')\n",
    "zero = [1,0,0,2,3,4,2,1]\n",
    "one = [2,1,2,4,4,6,3,3]\n",
    "two = [4,2,3,6,7,8,5,5]\n",
    "three = [7,1,6,9,10,12,8,7]\n",
    "a = [zero,one,two,three]\n",
    "Anova_pvalue_HSD(a,0.05)\n",
    "print('At .05 significance level, df_within = 28, df_between = 3, reject Null hypothesis because F_ratio = 10.836158192090394 is greater than F = 2.95')\n",
    "\n",
    "print('\\n')\n",
    "print('TRIAL')\n",
    "X0 = [1,3,6,2,1]\n",
    "X24 = [4,7,5]\n",
    "X48 = [7,12,10,9]\n",
    "X44 = [4,9,10,15,4]\n",
    "a = [X0,X24,X48,X44]\n",
    "Anova_pvalue_HSD(a,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e3121b-30cd-4c19-b251-ca0445baac7b",
   "metadata": {},
   "source": [
    "#### Progress Check *16.7 Given the rejection of the null hypothesis in Question 16.5, Tukey’s HSD test can be used to identify pairs of population means that differ. Using the .05 level of significance, calculate the critical value for HSD and use it to evaluate the statistical significance of each possible mean difference. Use the matrix shown in Table 16.8 as a model. The various sample means are $\\overline{X}_0 = 1.63, \\overline{X}_1 = 3.13, \\overline{X}_2 = 5.00$, and $\\overline{X}_3 = 7.50$.\n",
    "(a) Estimate the standardized effect size for any significant pair of mean differences with Cohen’s d.\n",
    "\n",
    "(b) Interpret the results of your analysis.\n",
    "\n",
    "$d=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{s^2_p}}=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{MS_{within}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9e1ccb-df94-4799-a48f-b3157f40d129",
   "metadata": {},
   "source": [
    "\\begin{array}{ccc}\n",
    "\\text{} & \\overline{X}_0=1.63 & \\overline{X}_1=3.13 & \\overline{X}_2=5.00 & \\overline{X}_3=7.50 \\\\\n",
    "\\hline\n",
    "\\overline{X}_0=1.63 & - & 1.5 & 3.37 & 5.87 \\\\\n",
    "\\overline{X}_1=3.13 & - & - & 1.87 & 4.37 \\\\\n",
    "\\overline{X}_2=5.00 & - & - & - & 2.5 \\\\\n",
    "\\overline{X}_3=7.50 & - & - & - & -\\\\\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9728150c-0ee8-47f4-93c5-0bba8c0dbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MS_within = 4.741071428571429 #from 16.5\n",
    "dX3X0 = 5.87/math.sqrt(MS_within)\n",
    "dX2X0 = 3.37/math.sqrt(MS_within)\n",
    "dX3X1 = 4.37/math.sqrt(MS_within)\n",
    "print(f'dX3X0 = {dX3X0}\\ndX2X0 = {dX2X0}\\ndX3X1 = {dX3X1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85414fd8-2a62-4199-823a-df2f06ef5d63",
   "metadata": {},
   "source": [
    "#### 16.11 The investigator mentioned in Review Question 14.14 wishes to conduct a more extensive test of the effect of alcohol consumption on the performance of automobile drivers, possibly to gain more information about the legal maximum for DUI arrests. Before the driving test, subjects drink a glass of orange juice laced with controlled amounts of vodka. Their performance is measured by the number of errors on a driving simulator. Five subjects are randomly assigned to each of five groups receiving different amounts of vodka (either 0, 1, 2, 4, or 6 ounces), and the following results were obtained:\n",
    "DRIVING ERRORS AS A FUNCTION OF ALCOHOL CONSUMPTION (OUNCES)\n",
    "\\begin{array}{ccc}\n",
    "\\text{} &  &  &  &  \\\\\n",
    "\\hline\n",
    "ZERO & ONE & TWO & FOUR & SIX \\\\\n",
    "1 & 4 & 6 & 15 & 20 \\\\\n",
    "1 & 3 & 1 & 6 & 25 \\\\\n",
    "3 & 1 & 2 & 9 & 10 \\\\\n",
    "6 & 7 & 10 & 17 & 10 \\\\\n",
    "4 & 5 & 7 & 9 & 9 \\\\\n",
    "\\end{array}\n",
    "\n",
    "(a) Summarize the results with an ANOVA table. (Note: Save these results for use with Review Question 17.7.)\n",
    "\n",
    "(b) If appropriate, estimate the effect size with $\\eta^2$.\n",
    "\n",
    "$HSD=q\\sqrt{\\dfrac{MS_{within}}{n}}$\n",
    "\n",
    "(c) If appropriate, use Tukey’s HSD test to pinpoint pairs of means that contribute to the significant F, given that $\\overline{X}_0 = 3, \\overline{X}_1 = 4, \\overline{X}_2 = 5.2, \\overline{X}_4 = 11.2$, and $\\overline{X}_6 = 14.8$. Furthermore, if appropriate, estimate effect sizes with Cohen’s d.\n",
    "\n",
    "$d=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{s^2_p}}=\\dfrac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{MS_{within}}}$\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{} & \\overline{X}_0=3 & \\overline{X}_1=4 & \\overline{X}_2=5.2 & \\overline{X}_4=11.2 & \\overline{X}_6=14.8 \\\\\n",
    "\\hline\n",
    "\\overline{X}_0=3 & - & 1 & 2.2 & 8.2 & 11.8 \\\\\n",
    "\\overline{X}_1=4 & - & - & 1 & 7.2 & 10.8 \\\\\n",
    "\\overline{X}_2=5.2 & - & - & - & 6 & 9.6 \\\\\n",
    "\\overline{X}_4=11.2 & - & - & - & - & 3.6 \\\\\n",
    "\\overline{X}_6=14.8 & - & - & - & -\\\\\n",
    "\\end{array}\n",
    "\n",
    "### Cohen's Guidelines for d\n",
    "\n",
    "| d | EFFECT SIZE \n",
    "|:---------:|:--------:|\n",
    "|  0.20 |  small  |\n",
    "|  0.50  | medium |\n",
    "|  0.80  |  large  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef6599d-e573-4fe1-88bc-e6188239178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16.11\n",
    "zero = [1,1,3,6,4]\n",
    "one = [4,3,1,7,5]\n",
    "two = [6,1,2,10,7]\n",
    "four = [15,6,9,17,9]\n",
    "six = [20,25,10,10,9]\n",
    "a = [zero,one,two,four,six]\n",
    "# mean of each sample verification\n",
    "mean = [statistics.mean(sample) for sample in a]\n",
    "print(f'mean of each sample = {mean}')\n",
    "\n",
    "SS_terms_ANOVA(a)\n",
    "# At .05 significance level, df_between = 4, df_within = 20, F_critical = 2.87, since the observed value of F_ratio = 6.7373841400617955\n",
    "# is larger, we reject the null hypothesis\n",
    "\n",
    "# At .05 significance level, df_within = 20, k = 5, the critical value of q = 4.23\n",
    "q = 4.23\n",
    "n = 5\n",
    "MS_within = 19.419999999999995\n",
    "HSD = q*math.sqrt(MS_within/n)\n",
    "print(f'HSD = {HSD}')\n",
    "\n",
    "dX6X0 = 11.8/math.sqrt(MS_within)\n",
    "dX6X1 = 10.8/math.sqrt(MS_within)\n",
    "dX6X2 = 9.6/math.sqrt(MS_within)\n",
    "dX4X0 = 8.2/math.sqrt(MS_within)\n",
    "print(f'dX6X0 = {dX6X0}\\ndX6X1 = {dX6X1}\\ndX6X2 = {dX6X2}\\ndX4X0 = {dX4X0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52530c17-7778-4dbe-95d9-8946574ba984",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [1,1,3,6,4]\n",
    "one = [4,3,1,7,5]\n",
    "two = [6,1,2,10,7]\n",
    "four = [15,6,9,17,9]\n",
    "six = [20,25,10,10,9]\n",
    "a = [zero,one,two,four,six]\n",
    "Anova_pvalue_HSD(a,0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb9078-1462-4bfc-8cd8-d295e041ad40",
   "metadata": {},
   "source": [
    "#### 16.13 Twenty-three overweight male volunteers are randomly assigned to three different treatment programs designed to produce a weight loss by focusing on either diet, exercise, or the modification of eating behavior. Weight changes were recorded, to the nearest pound, for all participants who completed the two-month experiment. Positive scores signify a weight drop; negative scores, a weight gain.\n",
    "WEIGHT CHANGES\n",
    "\n",
    "\\begin{array}{ccc}\n",
    "\\text{} &  &  &  &  \\\\\n",
    "\\hline\n",
    "DIET & EXERCISE & BEHAVIOR~MODIFICATION\\\\\n",
    "3 & -1 & 7 \\\\\n",
    "4 & 8 & 1 \\\\\n",
    "0 & 4 & 10 \\\\\n",
    "-3 & 2 & 0 \\\\\n",
    "5 & 2 & 18 \\\\\n",
    "10 & -3 & 12 \\\\\n",
    "3 &  & 4 \\\\\n",
    "0 &  & 6 \\\\\n",
    " &  & 5 \\\\\n",
    "\\end{array}\n",
    "\n",
    "(a) Summarize the results with an ANOVA table.\n",
    "\n",
    "(b) Whenever appropriate, use Tukey’s HSD test and estimate all effect sizes, given that the means for diet, exercise, and behavior modification equal 2.75, 2.00, and 7.00, respectively.\n",
    "\n",
    "$HSD=q\\sqrt{\\dfrac{MS_{within}}{n}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b14c2-227d-4ab2-acfb-c22b808b6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "diet = [3,4,0,-3,5,10,3,0]\n",
    "exercise = [-1,8,4,2,2,-3]\n",
    "behavior_modification = [7,1,10,0,18,12,4,6,5]\n",
    "a = [diet,exercise,behavior_modification]\n",
    "means = [statistics.mean(sample) for sample in a]\n",
    "SS_terms_ANOVA(a)\n",
    "\n",
    "# At .05 significance level, df_within = 20, df_between = 2, the critical value of F = 3.49, the observed value of \n",
    "# F_ratio = 2.6730894024858984, which is smaller so we retain the null hypothesis\n",
    "\n",
    "# At .05 significance level, df_within = 20, k = 3, the critical value of q = 3.58\n",
    "q = 3.58\n",
    "SS_within = 435.5\n",
    "n = 23\n",
    "HSD = 2.0859634472658364*math.sqrt(SS_within/n)\n",
    "print(f'HSD = {HSD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028c991-4fbb-443f-afbe-0147977df9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "diet = [3,4,0,-3,5,10,3,0]\n",
    "exercise = [-1,8,4,2,2,-3]\n",
    "behavior_modification = [7,1,10,0,18,12,4,6,5]\n",
    "a = [diet,exercise,behavior_modification]\n",
    "Anova_pvalue_HSD(a,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b27ba-9bf3-455c-9596-491f1136b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [1,0,0,2,3,4,2,1]\n",
    "one = [2,1,2,4,4,6,3,3]\n",
    "two = [4,2,3,6,7,8,5,5]\n",
    "three = [7,6,6,7,9,10,8,7]\n",
    "list = [zero,one,two,three]\n",
    "Anova_pvalue_HSD(list,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab286dc-e275-4290-999f-5fb961f7b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [1,1,3,6,4]\n",
    "one = [4,3,1,7,5]\n",
    "two = [6,1,2,10,7]\n",
    "four = [15,6,9,17,9]\n",
    "six = [20,25,10,10,9]\n",
    "data = [zero,one,two,four,six]\n",
    "sig = 0.05\n",
    "Anova_pvalue_HSD(data,sig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
