{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc2b41c9-ba67-4d53-acda-24368f33aad9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# TV_FAVORABLE = [12,4,5,20,5,5,20,10,49]\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# TV_UNFAVORABLE = [43,14,42,1,2,0,1,0,0]\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[43mX1\u001b[49m,X2]\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mboxplot(data)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X1' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TV_FAVORABLE = [12,4,5,20,5,5,20,10,49]\n",
    "# TV_UNFAVORABLE = [43,14,42,1,2,0,1,0,0]\n",
    "\n",
    "\n",
    "data = [X1,X2]\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e432cec-4635-4197-b66d-e79bbe66c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X1 = [12,5,11,11,9,18]\n",
    "# X2 = [7,3,4,6,3,13]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "TV_FAVORABLE = [12,4,5,20,5,5,20,10,49]\n",
    "TV_UNFAVORABLE = [43,14,42,1,2,0,1,0,0]\n",
    "\n",
    "# Create multiple histograms\n",
    "plt.hist(TV_FAVORABLE, alpha=0.5, label='Data 1')\n",
    "plt.hist(TV_UNFAVORABLE, alpha=0.5, label='Data 2')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Multiple Histograms')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce31eab-e4e4-4022-bc3c-97bc0707b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 19\n",
    "\n",
    "# Critical value of t (lower tail)\n",
    "t_critical = -2.41\n",
    "\n",
    "# Calculate the p-value for the lower tail\n",
    "p_value = t.sf(abs(t_critical), df)\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45695aaf-525d-4774-8966-daca28e6f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 19\n",
    "\n",
    "# Critical value of t (lower tail)\n",
    "t_critical = -2.41\n",
    "\n",
    "# Calculate the p-value for the lower tail\n",
    "p_value_lower = t.sf(abs(t_critical), df)\n",
    "print(p_value_lower)\n",
    "# For a two-tailed test, we need to consider both tails\n",
    "p_value = 2 * p_value_lower\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value < 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc54e5-9c97-4dee-8fb0-e4c362e34b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-tailed test; df = 15; t = 3.76\n",
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 15\n",
    "\n",
    "# Critical value of t (lower tail)\n",
    "t_critical = 3.76\n",
    "\n",
    "# Calculate the p-value for the lower tail\n",
    "p_value_lower = t.sf(abs(t_critical), df)\n",
    "print(p_value_lower)\n",
    "# For a two-tailed test, we need to consider both tails\n",
    "p_value = 2 * p_value_lower\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c8fc0-1f74-4607-8268-ba5933fa074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# two-tailed test; df = 42; t = 1.305 Answer: p > 0.05\n",
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 42\n",
    "\n",
    "# Critical value of t (lower tail)\n",
    "t_critical = 1.305\n",
    "\n",
    "# Calculate the p-value for the lower tail\n",
    "p_value_lower = t.sf(abs(t_critical), df)\n",
    "print(p_value_lower)\n",
    "# For a two-tailed test, we need to consider both tails\n",
    "p_value = 2 * p_value_lower\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value > 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af5eec-d9c5-464e-bfa3-e912547bdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-tailed test, upper tail critical; df = 11; t = –4.23 (Be careful!) Answer: p > 0.05\n",
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 11\n",
    "\n",
    "# Critical value of t (lower tail)\n",
    "t_critical = -4.23\n",
    "\n",
    "# Calculate the p-value for the lower tail\n",
    "p_value_lower = t.sf(abs(t_critical), df)\n",
    "print(p_value_lower)\n",
    "# For a two-tailed test, we need to consider both tails\n",
    "p_value = 2 * p_value_lower\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value > 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b3625-532f-4e99-a1d3-210b9332ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "# Degrees of freedom\n",
    "df = 11\n",
    "\n",
    "# Critical value of t (upper tail)\n",
    "t_critical = -4.23\n",
    "\n",
    "# Calculate the p-value for the upper tail\n",
    "p_value = t.sf(abs(t_critical), df)\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "print(p_value > 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0fd98-c902-4812-b91c-c3213b684162",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "COMMITTEE = [2, 5, 20, 15, 4, 10]\n",
    "SOLITARY = [3, 8, 7, 10, 14, 0]\n",
    "\n",
    "# Hypothesized mean\n",
    "hypothesized_mean = 0\n",
    "\n",
    "# Calculate sample statistics\n",
    "mean_committee = np.mean(COMMITTEE)\n",
    "mean_solitary = np.mean(SOLITARY)\n",
    "std_committee = np.std(COMMITTEE, ddof=1)\n",
    "std_solitary = np.std(SOLITARY, ddof=1)\n",
    "n_committee = len(COMMITTEE)\n",
    "n_solitary = len(SOLITARY)\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = (mean_committee - mean_solitary) / np.sqrt((std_committee**2 / n_committee) + (std_solitary**2 / n_solitary))\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n_committee + n_solitary - 2\n",
    "\n",
    "# Calculate critical value of t for a two-tailed test\n",
    "alpha = 0.05\n",
    "critical_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = 2 * (1 - t.cdf(abs(t_statistic), df))\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ae9d9-423b-4bf4-92cc-735cf5ea2bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "COMMITTEE = [2, 5, 20, 15, 4, 10]\n",
    "SOLITARY = [3, 8, 7, 10, 14, 0]\n",
    "\n",
    "# Hypothesized mean\n",
    "hypothesized_mean = 0\n",
    "\n",
    "# Calculate sample statistics\n",
    "mean_committee = np.mean(COMMITTEE)\n",
    "mean_solitary = np.mean(SOLITARY)\n",
    "std_committee = np.std(COMMITTEE, ddof=1)\n",
    "std_solitary = np.std(SOLITARY, ddof=1)\n",
    "n_committee = len(COMMITTEE)\n",
    "n_solitary = len(SOLITARY)\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = (mean_committee - mean_solitary) / np.sqrt((std_committee**2 / n_committee) + (std_solitary**2 / n_solitary))\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n_committee + n_solitary - 2\n",
    "\n",
    "# Calculate critical value of t for a one-tailed test\n",
    "alpha = 0.05\n",
    "critical_value = t.ppf(1 - alpha, df)\n",
    "\n",
    "# Calculate p-value for one-tailed test (upper tail)\n",
    "p_value = 1 - t.cdf(abs(t_statistic), df)\n",
    "# p_value = 2 * (1 - t.cdf(abs(t_statistic), df))\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a82663-31d4-49de-ad0c-09318575b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-tailed test, upper tail critical; df = 11; t = –4.23 (Be careful!)\n",
    "from scipy.stats import t\n",
    "alpha = 0.05\n",
    "df = 11\n",
    "tail = 1\n",
    "t_critical = round(t.ppf(1 - alpha/tail, df),3)\n",
    "print(f't_critical = {t_critical}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c57d7d-6790-4dc6-b723-c65f5fece0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "sample1 = [12, 5, 11, 11, 9, 18]\n",
    "sample2 = [7, 3, 4, 6, 3, 13]\n",
    "\n",
    "# Hypothesized mean\n",
    "hypothesized_mean = 0\n",
    "\n",
    "# Calculate sample statistics\n",
    "mean_sample1 = np.mean(sample1)\n",
    "mean_sample2 = np.mean(sample2)\n",
    "std_sample1 = np.std(sample1, ddof=1)\n",
    "std_sample2 = np.std(sample2, ddof=1)\n",
    "n_sample1 = len(sample1)\n",
    "n_sample2 = len(sample2)\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = (mean_sample1 - mean_sample2) / np.sqrt((std_sample1**2 / n_sample1) + (std_sample2**2 / n_sample2))\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n_sample1 + n_sample2 - 2\n",
    "\n",
    "# Calculate critical value of t for a two-tailed test\n",
    "alpha = 0.05\n",
    "critical_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "# Calculate confidence intervals\n",
    "SE = np.sqrt((std_sample1**2 / n_sample1) + (std_sample2**2 / n_sample2))\n",
    "margin_of_error = critical_value * SE\n",
    "confidence_interval_lower = (mean_sample1 - mean_sample2) - margin_of_error\n",
    "confidence_interval_upper = (mean_sample1 - mean_sample2) + margin_of_error\n",
    "print(margin_of_error)\n",
    "print(SE)\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"Confidence interval:\", (confidence_interval_lower, confidence_interval_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b3a84-d497-4f1e-beda-d5b5af20729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "sample1 = [12, 5, 11, 11, 9, 18]\n",
    "sample2 = [7, 3, 4, 6, 3, 13]\n",
    "\n",
    "# Hypothesized mean\n",
    "hypothesized_mean = 0\n",
    "\n",
    "# Calculate sample statistics\n",
    "mean_sample1 = np.mean(sample1)\n",
    "mean_sample2 = np.mean(sample2)\n",
    "std_sample1 = np.std(sample1, ddof=1)\n",
    "std_sample2 = np.std(sample2, ddof=1)\n",
    "n_sample1 = len(sample1)\n",
    "n_sample2 = len(sample2)\n",
    "\n",
    "# Calculate t-statistic\n",
    "t_statistic = (mean_sample1 - mean_sample2) / np.sqrt((std_sample1**2 / n_sample1) + (std_sample2**2 / n_sample2))\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n_sample1 + n_sample2 - 2\n",
    "\n",
    "# Calculate critical value of t for a two-tailed test\n",
    "alpha = 0.05\n",
    "critical_value = t.ppf(1 - alpha/2, df)\n",
    "\n",
    "# Calculate confidence intervals\n",
    "SE = np.sqrt((std_sample1**2 / n_sample1) + (std_sample2**2 / n_sample2))\n",
    "margin_of_error = critical_value * SE\n",
    "confidence_interval_lower = (mean_sample1 - mean_sample2) - margin_of_error\n",
    "confidence_interval_upper = (mean_sample1 - mean_sample2) + margin_of_error\n",
    "\n",
    "# Calculate Cohen's d effect size\n",
    "pooled_std = np.sqrt((std_sample1**2 + std_sample2**2) / 2)\n",
    "cohens_d = (mean_sample1 - mean_sample2) / pooled_std\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"Confidence interval:\", (confidence_interval_lower, confidence_interval_upper))\n",
    "print(\"Cohen's d effect size:\", cohens_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67c04a-e8fc-4e31-af39-836a7bbc2445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "sample1 = [12,5,11,11,9,18]\n",
    "sample2 = [7,3,4,6,3,13]\n",
    "print(statistics.stdev(sample1))\n",
    "print(statistics.stdev(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1e19d-419e-49ba-8dbb-9ea3db898f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "alpha = 0.05\n",
    "tail = 1\n",
    "df = 5\n",
    "t_critical = round(t.ppf(1 - alpha/tail, df),3)\n",
    "t_critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c46180d-767e-464a-90bc-f289c7e12a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X1 = [4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80]\n",
    "X2 = [3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65]\n",
    "\n",
    "# Compute differences between paired observations\n",
    "differences = np.array(X1) - np.array(X2)\n",
    "\n",
    "# Calculate mean and standard deviation of the differences\n",
    "mean_difference = np.mean(differences)\n",
    "std_difference = np.std(differences, ddof=1)\n",
    "\n",
    "# Calculate standard error of the mean difference\n",
    "n = len(differences)\n",
    "SE = std_difference / np.sqrt(n)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_statistic = mean_difference / SE\n",
    "\n",
    "# Determine degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate critical value of t for a one-tailed test\n",
    "critical_value = t.ppf(1 - significance_level, df)\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d32012-f53b-47bc-9ce7-1874e4c4e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X1 = [4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80]\n",
    "X2 = [3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65]\n",
    "\n",
    "# Compute differences between paired observations\n",
    "differences = np.array(X1) - np.array(X2)\n",
    "\n",
    "# Calculate mean and standard deviation of the differences\n",
    "mean_difference = np.mean(differences)\n",
    "std_difference = np.std(differences, ddof=1)\n",
    "\n",
    "# Calculate standard error of the mean difference\n",
    "n = len(differences)\n",
    "SE = std_difference / np.sqrt(n)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_statistic = mean_difference / SE\n",
    "\n",
    "# Determine degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate critical value of t for a one-tailed test\n",
    "critical_value = t.ppf(1 - significance_level, df)\n",
    "\n",
    "# Calculate confidence intervals for the mean difference\n",
    "margin_of_error = critical_value * SE\n",
    "confidence_interval_lower = mean_difference - margin_of_error\n",
    "confidence_interval_upper = mean_difference + margin_of_error\n",
    "\n",
    "# Calculate Cohen's d effect size\n",
    "cohens_d = mean_difference / std_difference\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"Confidence interval for the mean difference:\", (confidence_interval_lower, confidence_interval_upper))\n",
    "print(\"Cohen's d effect size:\", cohens_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74a8a5-18f4-4e50-a9e4-6e974015b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X1 = [4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80]\n",
    "X2 = [3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65]\n",
    "\n",
    "# Compute differences between paired observations\n",
    "differences = np.array(X1) - np.array(X2)\n",
    "\n",
    "# Calculate mean and standard deviation of the differences\n",
    "mean_difference = np.mean(differences)\n",
    "std_difference = np.std(differences, ddof=1)\n",
    "\n",
    "# Calculate standard error of the mean difference\n",
    "n = len(differences)\n",
    "SE = std_difference / np.sqrt(n)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_statistic = mean_difference / SE\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate the p-value for a one-tailed test\n",
    "p_value = t.cdf(t_statistic, df)\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3709c0d-2ff1-48c3-9750-4385ec403c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X1 = [4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80]\n",
    "X2 = [3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65]\n",
    "\n",
    "# Compute differences between paired observations\n",
    "differences = np.array(X1) - np.array(X2)\n",
    "\n",
    "# Calculate mean and standard deviation of the differences\n",
    "mean_difference = np.mean(differences)\n",
    "std_difference = np.std(differences, ddof=1)\n",
    "\n",
    "# Calculate standard error of the mean difference\n",
    "n = len(differences)\n",
    "SE = std_difference / np.sqrt(n)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_statistic = mean_difference / SE\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate critical value of t for a one-tailed test\n",
    "critical_value = t.ppf(1 - significance_level, df)\n",
    "\n",
    "# Calculate confidence intervals for the mean difference\n",
    "margin_of_error = critical_value * SE\n",
    "confidence_interval_lower = mean_difference - margin_of_error\n",
    "confidence_interval_upper = mean_difference + margin_of_error\n",
    "\n",
    "# Calculate Cohen's d effect size\n",
    "cohens_d = mean_difference / std_difference\n",
    "\n",
    "# Calculate the p-value for a one-tailed test\n",
    "p_value = t.cdf(t_statistic, df)\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"Confidence interval for the mean difference:\", (confidence_interval_lower, confidence_interval_upper))\n",
    "print(\"Cohen's d effect size:\", cohens_d)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b5a92-dd4c-4f3a-82f4-2c94f329b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "X1 = [4.00, 2.67, 3.65, 2.11, 3.21, 3.60, 2.80]\n",
    "X2 = [3.75, 2.74, 3.42, 1.67, 3.00, 3.25, 2.65]\n",
    "\n",
    "# Compute differences between paired observations\n",
    "differences = np.array(X1) - np.array(X2)\n",
    "\n",
    "# Calculate mean and standard deviation of the differences\n",
    "mean_difference = np.mean(differences)\n",
    "std_difference = np.std(differences, ddof=1)\n",
    "\n",
    "# Calculate standard error of the mean difference\n",
    "n = len(differences)\n",
    "SE = std_difference / np.sqrt(n)\n",
    "\n",
    "# Compute the t-statistic\n",
    "t_statistic = mean_difference / SE\n",
    "\n",
    "# Degrees of freedom\n",
    "df = n - 1\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.01\n",
    "\n",
    "# Calculate critical value of t for a two-tailed test\n",
    "critical_value = t.ppf(1 - significance_level/2, df)\n",
    "\n",
    "# Calculate confidence intervals for the mean difference\n",
    "margin_of_error = critical_value * SE\n",
    "confidence_interval_lower = mean_difference - margin_of_error\n",
    "confidence_interval_upper = mean_difference + margin_of_error\n",
    "\n",
    "# Calculate Cohen's d effect size\n",
    "cohens_d = mean_difference / std_difference\n",
    "\n",
    "# Calculate the p-value for a two-tailed test\n",
    "# p_value_two_tail = 2*t.cdf(-abs(t_statistic), df)\n",
    "\n",
    "p_value_one_tail = t.cdf(t_statistic, df)\n",
    "\n",
    "print(\"Observed t-statistic:\", t_statistic)\n",
    "print(\"Critical value of t:\", critical_value)\n",
    "print(\"Confidence interval for the mean difference:\", (confidence_interval_lower, confidence_interval_upper))\n",
    "print(\"Cohen's d effect size:\", cohens_d)\n",
    "print(\"p-value:\", p_value_one_tail)\n",
    "\n",
    "# p-value: 0.010523873876434137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8a0ebb-473f-48c1-be68-c390fd474912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D_overline = -5\n",
      "sum_D = -25\n",
      "sum_of_sq_of_each_D = 157\n",
      "SSD = 32.0\n",
      "sample_standard_deviation_SD = 2.828\n",
      "est_std_error = 1.265\n",
      "t_ratio = -3.953\n",
      "Cohen's d = -1.768\n",
      "df = 4\n",
      "critical_value_of_t = 2.776\n",
      "We have a confidence of 95% that the true mean is in between the values of -8.512 and -1.488\n"
     ]
    }
   ],
   "source": [
    "def t_test_repeated_measures_1(a,b,alpha,tail):\n",
    "    import statistics\n",
    "    import math\n",
    "    from scipy.stats import t\n",
    "\n",
    "    n = len(a)\n",
    "    X1_mean = statistics.mean(a)\n",
    "    X2_mean = statistics.mean(b)\n",
    "    D_overline = round(X1_mean - X2_mean,3)\n",
    "    print(f'D_overline = {D_overline}')\n",
    "    \n",
    "    D = [a[n]-b[n] for n in range(0,len(a))]\n",
    "\n",
    "    sum_D = round(sum(D),3)\n",
    "    print(f'sum_D = {sum_D}')\n",
    "\n",
    "    sq_of_each_D = [d**2 for d in D]\n",
    "    # print(f'sq_of_each_D = {sq_of_each_D}')\n",
    "\n",
    "    sum_of_sq_of_each_D = round(sum(sq_of_each_D),3)\n",
    "    print(f'sum_of_sq_of_each_D = {sum_of_sq_of_each_D}')\n",
    "\n",
    "    SSD = round(sum_of_sq_of_each_D - (sum_D**2/n),3)\n",
    "    print(f'SSD = {SSD}')\n",
    "\n",
    "    sample_standard_deviation_SD = round(math.sqrt(SSD/(n-1)),3)\n",
    "    print(f'sample_standard_deviation_SD = {sample_standard_deviation_SD}')\n",
    "\n",
    "    est_std_error = round(sample_standard_deviation_SD/math.sqrt(n),3)\n",
    "    print(f'est_std_error = {est_std_error}')\n",
    "\n",
    "    t_ratio = round((D_overline-0)/est_std_error,3)\n",
    "    print(f't_ratio = {t_ratio}')\n",
    "\n",
    "    d = round(D_overline/sample_standard_deviation_SD,3)\n",
    "    print(f\"Cohen's d = {d}\")\n",
    "\n",
    "    df = len(a)-1\n",
    "    print(f'df = {df}')\n",
    "    \n",
    "    critical_value_of_t = round(t.ppf(1 - alpha / tail, df),3)\n",
    "    print(f'critical_value_of_t = {critical_value_of_t}')\n",
    "    \n",
    "    CI1 = round(D_overline - (critical_value_of_t*est_std_error),3)\n",
    "    CI2 = round(D_overline + (critical_value_of_t*est_std_error),3)\n",
    "    print(f'We have a confidence of {round((1-alpha)*100)}% that the true mean is in between the values of {CI1} and {CI2}')\n",
    "    \n",
    "sent = [5,7,13,9,1]\n",
    "received = [10,12,14,18,6]\n",
    "sig = 0.05\n",
    "tail = 2\n",
    "t_test_repeated_measures_1(sent,received,sig,tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a92d179-47de-4c1b-8d81-a778b921c280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.5099800796022267\n",
      "p-value: 0.040398095491595926\n",
      "Reject the null hypothesis: There is a significant difference between the two related samples.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Sample data\n",
    "# X1 = [341, 335, 327, 324, 317, 314, 314, 313, 311, 306]\n",
    "# X2 = [313, 282, 310, 287, 290, 287, 292, 338, 318, 306]\n",
    "X1 = [28,29,31,44,35,20,50,25]\n",
    "X2 = [26,27,32,44,35,16,47,23]\n",
    "# Perform t-test for related samples\n",
    "t_statistic, p_value = ttest_rel(X1, X2)\n",
    "\n",
    "# Set significance level\n",
    "significance_level = 0.05\n",
    "\n",
    "# Print the results\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Test the null hypothesis\n",
    "if p_value < significance_level:\n",
    "    print(\"Reject the null hypothesis: There is a significant difference between the two related samples.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two related samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af7db7d-23c2-406a-8c7d-07b52d7478de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.51\n"
     ]
    }
   ],
   "source": [
    "X1 = [28,29,31,44,35,20,50,25]\n",
    "X2 = [26,27,32,44,35,16,47,23]\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "t_rat, pval = ttest_rel(X1,X2)\n",
    "\n",
    "t_ration = round(t_rat,3)\n",
    "print(t_ration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0530720-0475-4192-bfdc-404e3ce9cfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
